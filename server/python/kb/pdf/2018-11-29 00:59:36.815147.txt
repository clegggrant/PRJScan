Hindawi Computational Intelligence and Neuroscience Volume 2018, Article ID 9704672, 11 pages https://doi.org/10.1155/2018/9704672 Research Article Machine-Learning Approach to Optimize SMOTE Ratio in Class Imbalance Dataset for Intrusion Detection Jae-Hyun Seo 1 and Yong-Hyuk Kim 2 1Department of Computer Science and Engineering, Wonkwang University, 460 Iksandae-ro, Iksan-si, Jeonbuk 54649, Republic of Korea 2School of Software, Kwangwoon University, 20 Kwangwoon-ro, Nowon-gu, Seoul 01897, Republic of Korea Correspondence should be addressed to Yong-Hyuk Kim; yhdﬂy@kw.ac.kr Received 30 April 2018; Revised 6 August 2018; Accepted 2 October 2018; Published 1 November 2018 Academic Editor: Giosu`e Lo Bosco Copyright © 2018 Jae-Hyun Seo and Yong-Hyuk Kim. 1is is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. 1e KDD CUP 1999 intrusion detection dataset was introduced at the third international knowledge discovery and data mining tools competition, and it has been widely used for many studies. 1e attack types of KDD CUP 1999 dataset are divided into four categories: user to root (U2R), remote to local (R2L), denial of service (DoS), and Probe. We use ﬁve classes by adding the normal class. We deﬁne the U2R, R2L, and Probe classes, which are each less than 1% of the total dataset, as rare classes. In this study, we attempt to mitigate the class imbalance of the dataset. Using the synthetic minority oversampling technique (SMOTE), we attempted to optimize the SMOTE ratios for the rare classes (U2R, R2L, and Probe). After randomly generating a number of tuples of SMOTE ratios, these tuples were used to create a numerical model for optimizing the SMOTE ratios of the rare classes. 1e support vector regression was used to create the model. We assigned each instance in the test dataset to the model and chose the best SMOTE ratios. 1e experiments using machine-learning techniques were conducted using the best ratios. 1e results using the proposed method were signiﬁcantly better than those of previous approach and other related work. 1. Introduction 1e early IDS (intrusion detection system) [1] is divided into the host-based IDS (HIDS) and the network-based IDS (NIDS). HIDS has the advantage of analyzing the system log and resource usage information by the host and user. However, installing an IDS in each host increases the management points and wastes more resources. If network- level packet analysis is not possible and the attacker takes control of the system, the IDS may be interrupted. NIDS has advantages that it does not need to install an IDS on each host, and NIDS can perform analysis at the entire network level. However, there is a disadvantage in which it is possible to conﬁrm only the attack via the IDS, and it is diﬃcult to conﬁrm the attack attempt at the system level. In early 2003, the IDS was losing the trust of users due to the problem of generating false positives. 1e causes of false positives are due to the development of erroneous rules, traﬃc irregularities, and limitations of pattern matching tests. Even though the IDS problem has not been solved to date, “pattern matching” is still being used as a basis for security solutions. Intrusion detection attacks [2] are divided into misuse detection and anomaly detection. In misuse detection, de- tected attacks are compared with existing signatures in the database to determine whether they are intrusions. While misuse detection detects only the known attacks, anomaly detection detects a new type of attack that has a pattern diﬀerent from the normal traﬃc and the known attack types. Many researchers have studied intrusion detection. In general, researchers attempted to distinguish the normal class from attack classes using the publicly available intrusion detection evaluation dataset and to identify the exact attack type. However, the classiﬁcation of rare classes in a huge real- time dataset requires a long computation time, and then it is diﬃcult to achieve good eﬃciency. It is necessary to create and test many experimental datasets to improve classiﬁcation performance by adjusting the class ratio. 2 Computational Intelligence and Neuroscience In this paper, we present a novel method that optimally adjusts the SMOTE [3] ratios for rare classes. 1e number of cases for the tuple of SMOTE ratios is too large to test all the cases. For that reason, we propose the following eﬃcient method. We randomly generated some tuples of SMOTE ratios and used these tuples to create a model using a support vector regression (SVR) [4]. We input a number of tuples for SMOTE ratios to the SVR model, and we chose the best tuple of SMOTE ratios. Experimental results using the proposed method were signiﬁcantly better than those of the previous approach [5]. 1e contributions we make through the proposed method are given as follows. We suggest how to ﬁnd the SMOTE ratios that show good performance with very few tests. Hence, we dramatically reduce the amount of computations required to ﬁnd the best SMOTE ratios. We are sure that the proposed method is helpful for the study of class imbalances. 1e remainder of this paper is organized as follows. Section 2 explains the related works on the KDD CUP 1999 dataset [6] and class imbalances. In Section 3, we present the background of this research. In Section 4, we suggest a new method by creating a numerical model using sampled SMOTE ratios. In Section 5, we explain our experimental environments, procedures, and results. 1e paper ends with our concluding remarks in Section 6. 2. Related Work 2.1. KDD Dataset. Leung and Leckie [7] studied anomaly detection using unsupervised learning algorithms on the KDD CUP 1999 intrusion detection dataset. 1ese re- searchers proposed density-based clustering and grid-based clustering algorithms. In density-based clustering, a cluster includes a minimum number of data points. 1e approach has the advantage of ﬁltering outliers or ﬁnding clusters with arbitrary shapes. In the grid-based approach, all clustering operations are conducted on a grid structure. 1e method has the advantage of a fast computing speed. With the method, a classiﬁer can learn from unlabeled data and detect new types of attacks that were previously unseen. 1e ex- perimental results showed that the accuracy of their method is similar to one of existing methods, and the method has several advantages in terms of computational complexity. Meng [8] studied intrusion detection machine-learning techniques on the KDD CUP 1999 dataset. 1ere have been many studies using popular methods, such as artiﬁcial neural networks, SVM [9], and decision trees. However, these methods were rarely used in large-scale real intrusion de- tection systems. 1is researcher aimed at practical anomaly detection and conducted a comparative study with artiﬁcial neural networks, SVMs, and decision trees using the same environment as previous studies. In the analysis of the experimental results, the intrusion detection system with machine-learning techniques showed a high dependency on the test environment, and this researcher concluded that it was important to ﬁnd a suitable method for applying machine-learning techniques to real environments. Davis and Clark [10] reviewed the data preprocessing techniques used in anomaly-based network intrusion detection systems. 1e research focused on network traﬃc analysis and feature extraction/selection. Most of studies on NIDS dealt with the TCP/IP packet headers of network traﬃc. Time-based statistics can be derived from the headers to detect network scans, network worms, and DoS attacks. Recent, full service responses are analyzed to detect attacks targeting clients. 1is focuses on which attack classes can be detected by the reviewed methods. 1is review shows the trends that scrutinize packets to extract or select the most relevant fea- tures through targeted content parsing. 1ese context- sensitive features are required to detect network attacks. Staudemeyer and Omlin [11] used a long short-term memory recurrent neural network (LSTM-RNN) to evaluate the classiﬁcation performance using the KDD CUP 1999 dataset. LSTM networks can learn “memory” and create a model with time series data. 1e LSTM is trained and tested on their modiﬁed KDD CUP 1999 dataset. 1e LSTM network structure and parameters were obtained through experiments. Several performance measures were used to analyze experimental results. 1eir results showed that LSTM-RNN can learn all the unknown attack classes in the training dataset. Furthermore, they found that both receiver operating characteristic (ROC) curves and area under the curve (AUC) were well suited for evaluating LSTM-RNN. Kim et al. [12] proposed a system-call-language-modeling method based on LSTM for designing an anomaly-based host intrusion detection system. 1ese researchers used an en- semble method to solve the false-alarm rates problem that was common in conventional intrusion detection systems. 1e method can eﬀectively learn the semantic meaning and in- teractions of each system call that existing methods cannot handle. 1ese researchers demonstrated the validity and ef- fectiveness of their method through several tests on publicly available benchmark datasets, and their method has an ad- vantage in that it is easy to transplant to other systems. Kim et al. [13] investigated artiﬁcial intelligence intru- sion detection systems that used the deep neural network (DNN) and conducted experiments on the KDD CUP 1999 dataset. Data preprocessing (such as data transformation and normalization was conducted) was used to input the dataset into the DNN model. When a learning model was created, the DNN was used for data reﬁnement. 1e full dataset was used to verify the learning model. Performance measures, such as the accuracy, detection rate, and false- positive rate, were used to verify the detection eﬃciency of the DNN model, and the model showed good performance for intrusion detection. Le et al. [14] studied deep-learning algorithms to solve the problem of machine-learning techniques (such as SVM and k-NN) that had high false-positive rates in intrusion detection systems. 1ey found six optimizers that are ap- plicable to the LSTM-RNN model to be the best suited for intrusion detection systems. 1e LSTM results using the Nadam optimizer were better than previous approaches, with an accuracy of 97.54%, a detection rate of 98.95%, and a false-positive rate of 9.98%. In Table 1, the studies related to intrusion detection are summarized. Seo [5] tried to adjust the class imbalance of train data to detect attacks in the KDD 1999 intrusion dataset. He tested Computational Intelligence and Neuroscience 3 Table 1: Related work with KDD CUP 1999. Authors Leung and Leckie [7] Meng [8] Davis and Clark [10] Staudemeyer and Omlin [11] Kim et al. [12] Kim et al. [13] Le et al. [14] Seo [5] Year 2005 2011 2011 2013 2016 2017 2017 2017 Method Density-based and grid-based clustering SVM, neural networks, and decision tree Data preprocessing LSTM-RNN LSTM and ensemble DNN DNN SVM, k-NN, and decision tree with machine-learning algorithms to ﬁnd eﬃcient SMOTE ratios of rare classes such as U2R, R2L, and Probe. He studied to improve the performance of classiﬁcation fo- cusing on detection of rare classes. 1e number of instances of rare classes in the train data was increased by 12, 9, and 1.5 times, respectively. 1e recall metrics of k-NN tests were increased to 0.11 in U2R class and 0.02 in R2L class. 1e metrics of SVM tests were increased to 0.02 in U2R class and 0.08 in R2L class, and those of decision tree tests were in- creased to 0.25. 2.2. Class Imbalance. In the study of Japkowicz [15], most previously designed concept-learning systems assume that a training dataset is generally well balanced. 1is assumption is not necessarily correct. In practice, most instances represent one class, and only a small number of instances represent other ones. 1ese researchers tried to experimentally dem- onstrate that a class imbalance degrades the performance of standard classiﬁers. 1ese researchers compared the perfor- mance of several methods that were previously proposed by other researchers. Japkowicz and Stephen [16] studied class imbalance. Class imbalance has been reported to degrade the perfor- mance of some standard classiﬁers. 1ey conducted a sys- tematic study by answering the following three problems. First, they attempted to understand the concept complexity, the size of the training set, and the class imbalance level. Second, they discussed several basic resampling or cost- modifying methods to compare the eﬃciency of the pre- viously proposed class imbalance problems. Finally, they conducted studies with the assumption that class imbalance problems also aﬀected other classiﬁcation systems, such as decision trees, neural networks, and SVMs. Chawla et al. [17] studied the SMOTEBoost algorithm. In data mining, most of the datasets have the class imbalance problem, and data mining tools learn from imbalanced datasets. 1e classiﬁer, which learns from a minority class with very few instances, tends to be biased towards a high accuracy in the prediction of the majority class. SMOTE is used in the design of classiﬁers to train unbalanced datasets. 1ey pre- sented a new approach to learn from imbalanced datasets by combining the SMOTE algorithm and the boosting pro- cedure. Unlike standard boosting in which the same weight is given to all misclassiﬁed examples, SMOTEBoost generates synthetic examples from minority classes. SMOTEBoost in- directly changes the weight by updating and compensating for the skewed distribution. In the experiments with SMOTE- Boost applied to several datasets with a high or moderate class imbalance, the classiﬁcation performance for the minority class and the overall F-measure was improved. Drummond and Holte [18] used two commonly used sampling methods for applying machine learning to im- balanced classes and misclassiﬁcation costs. 1ey adopted a performance analysis technique called cost curves to ex- plore the interaction of oversampling and undersampling with the decision tree classiﬁer C4.5. 1ey showed that applying C4.5 to undersampling could establish a reasonable standard for comparing algorithms. However, it is recom- mended that the cheapest cost classiﬁer becomes a part of the standard since it can be better than undersampling for relatively modest costs. Oversampling has little inﬂuence on the sensitivity and the misclassiﬁcation costs have no sig- niﬁcant eﬀect on performance. Zhou and Liu [19] demonstrated the eﬀect of sampling and threshold-moving in training cost-sensitive neural networks. Both oversampling and undersampling were considered. 1ese techniques modiﬁed the distribution of training data so that the costs of the instances were explicitly conveyed by the appearances of the instances. 1reshold- moving moves the output threshold towards inexpensive classes to improve classiﬁcation performance. 1e hard- ensemble and soft-ensemble are used for the experiments. In hard-ensembles and soft-ensembles, all classiﬁers vote on each class and return the class that receives the most votes. 1e diﬀerence between the two ensembles is that hard- ensemble uses binary votes and soft-ensemble uses real- value votes. Twenty-one UCI datasets and actual datasets were used in their experiments. 1e experimental results showed that as the number of classes increases, the degree of class imbalance worsens and the eﬃciency of classiﬁca- tion deteriorates. 1reshold-moving and the soft-ensemble showed relatively good performance in training cost- sensitive neural networks. Liu et al. [9] used undersampling to solve the class im- balance problem. Undersampling is a very eﬀective method to mitigate class imbalance using only a subset of the majority class. 1e disadvantage of the method is that instances of majority classes are ignored. 1ey presented two algorithms to overcome the drawback. First, the EasyEnsemble algorithm samples several subsets from the majority class, trains a learner using each subset, and then combines the outputs of the learners. EasyEnsemble internally uses the AdaBoost ensemble. 1e BalanceCascade algorithm trains learners in sequence. At each step, instances of the majority class that are correctly classiﬁed by the current trained learners are re- moved from further consideration. 1e experimental results showed that both methods produce better solutions than the conventional class imbalance. Burez and Van den Poel [20] attempted to solve the class imbalance problem to predict customer churn. Customer churn is caused by a customer who changes service provider. Customer churn is a highly rare event in the service industry, but it is a notably interesting and informative research area. 4 However, the class imbalance problem in the context of data mining has not paid it considerable attention until recently. 1ey studied how class imbalance can be better handled in churn prediction. 1ey have conducted studies to improve the performance of random sampling and undersampling with appropriate evaluation matrices, such as AUC and lift. 1ey compared gradient boosting, weighted random forest modeling, and some standard modeling techniques. 1ey studied the performance of both random and advanced undersampling. 1ey compared the speciﬁc modeling techniques of gradient boosting and weighted random forests with some standard techniques. In their experiment, the use of undersampling improved the prediction accuracy and the AUC values. Seiﬀert et al. [21] had stated that class imbalance was a common problem in various applications. Several techniques had been used to mitigate class imbalance problems. 1ey used a hybrid sampling/boosting algorithm called RUSBoost to train skewed training dataset. 1e algorithm was simpler and faster as an alternative of SMOTEBoost. 1ey evaluated the performance of RUSBoost, SMOTEBoost, random undersampling, SMOTE, and AdaBoost. 1ey chose ﬁfteen datasets in various applications and then conducted experi- ments with four learners (C4.5D, C4.5N, naive Bayes (NB), and repeated incremental pruning) to produce error reduction (RIPPER) over four evaluation matrices. Both RUSBoost and SMOTEBoost were better than other methods, and RUSBoost performed equal to or better than SMOTEBoost. Horng et al. [22] proposed an SVM-based intrusion detection system. 1e system combines a hierarchical clus- tering algorithm, a simple feature selection procedure, and an SVM technique. 1e clustering algorithm provided the SVM with fewer, abstracted, and higher qualiﬁed training instances. It was able to shorten the training time and improve the performance of a resultant SVM. 1e obtained SVM model could classify the network traﬃc data more accurately through the simple feature selection procedure. 1e KDD Cup 1999 dataset was used to evaluate the proposed system. Compared with other intrusion detection systems that are based on the same dataset, this system showed better per- formance in the detection of DoS and Probe attacks, and the best performance in overall accuracy. In Table 2, the studies related to class imbalance are summarized. Computational Intelligence and Neuroscience Table 2: Related work with class imbalance. Method Decision tree and SVM SMOTE and SMOTEBoost Multilayer perceptron (MLP) Year Authors 2000 Japkowicz [15] Japkowicz and 2002 Stephen [16] 2003 Chawla et al. [17] Drummond and 2003 Holte [18] Zhou and Liu [19] 2006 Liu et al. [9] 2009 Burez and Van 2009 Gradient boosting and random forest den Poel [20] Seiﬀert et al. [21] 2010 Honrng et al. [22] 2011 RUSBoost, SMOTEBoost, SMOTE, and AdaBoost SVM and hierarchical clustering Cost-sensitive neural networks EasyEnsemble Decision tree dump data were generated over nine weeks. As in a real Air Force environment, the LAN was activated and various attacks were executed. However, there was a disadvantage in that there was no noise in the real data. However, the KDD CUP 1999 dataset served as a testbed to overcome the vulnerabilities of signature-based IDSs in detecting new attack types and attracted the attention of many researchers. 1e KDD CUP 1999 dataset is most widely used for the evaluation of such a system. 1ere are many previous ap- proaches using the dataset and it will be possible to compare the approaches with a new method. Table 3 represents the ﬁles in the KDD CUP 1999 dataset and the details for those. 1e ﬁles “kddcup.data_10_percent.gz” and “corrected.gz” are used as training data and test data, respectively. 1e training data are compressed binary TCP dump data collected over approximately seven weeks with approximately 5 million connection records. 1e testing data are collected over approximately two weeks. 1ey are com- posed of approximately 2 million connection records. Con- nection records are a collection of TCP packets ﬂowing from the source IP to the destination IP, and these are classiﬁed into a normal or attack class. In the case of connection records belonging to an attack class, these are represented by exactly one speciﬁc attack type. 1e size of each connection record is approximately 100 bytes. Attack types are categorized into four classes, such as DoS, R2L, U2R, and Probe, as shown in Table 4. 3. Background 3.1. KDD Dataset. 1e KDD CUP 1999 dataset [6] used in our experiments is a modiﬁcation of data generated by the DARPA (Defense Advanced Research Projects Agency) intrusion detection evaluation program in 1988. 1e DARPA dataset is intercepted data that contain a wide range of attacks generated in a military network environment. 1e dataset has greatly contributed to the investigation and evaluation of intrusion detection. 1e dataset has been prepared and managed by MIT’s Lincoln laboratory. In 1999, the modiﬁed DARPA dataset was used in the KDD CUP 1999 intrusion detection competition. MIT’s Lincoln laboratory has a similar experimental environment to the typical U. S. Air Force LAN (local area network). Raw TCP 3.2. SMOTE: Synthetic Minority Oversampling Technique. SMOTE [3] is a method of generating new instances using existing ones from rare or minority class. First, we identify the k-nearest neighbors in a class with a small number of instances and calculate the diﬀerences between a sample and these k neighbors. We multiply the diﬀerences by an arbi- trary value between 0 and 1 and get a resultant value. Next, an instance that is generated using the resultant value is added to the training data. As a result, SMOTE works by adding any points that slightly move existing instances around its neighbors. In the aspect of increasing the number of instances in rare classes, SMOTE is similar to random oversampling. However, it does not regenerate the same instance. It creates a new instance by appropriately Computational Intelligence and Neuroscience 5 Table 3: Train and test dataset with labels of KDD CUP 1999 dataset. Dataset Kddcup.data.gz Kddcup.data_10_percent.gz (23 attack types) Corrected.gz (23 attack types) Training dataset (743 MB) 10% subset of training Test dataset (45 MB) dataset (75 MB) Details Table 4: Five main categories of KDD CUP 1999 dataset. Attacks Normal DoS R2L U2R Probing Descriptions Normal traﬃc Denial of service, e.g., syn ﬂood Unauthorized access from a remote machine, e.g., guessing password Unauthorized access to local superuser (root) privileges, e.g., various “buﬀer overﬂow” attacks Surveillance and other probing, e.g., port scanning combining existing instances, thus making it possible to avoid the disadvantage of overﬁtting to a certain degree. 4. Modeling 4.1. Problem Deﬁnition. We attempt to maximize classiﬁ- cation performance of the KDD CUP 1999 intrusion de- tection dataset that has class imbalance. 1e dataset has severe class imbalance. 1erefore, data preprocessing for adjusting the class ratio is required to alleviate the imbal- ance. 1e class imbalance can be adjusted using under- sampling, oversampling, and SMOTE techniques. We use the SMOTE technique. All tuples of SMOTE ratios should be tested to optimize the ratios of each class. However, there are time and cost constraints to conduct experiments on all cases. 1erefore, we try to ﬁnd the tuple of SMOTE ratios that shows the best performance by experimenting with few tuples of SMOTE ratios. Formula (1) represents the method to calculate class imbalance ratio of each class. Figure 1 shows the structure of the dataset which is used in the proposed method. Table 5 shows class imbalance ratios of Train A, Train B which is the ﬁrst half of Train A, Validation which is the second half of Train A, and Test. Train A is the original train data. Train B and Validation in Table 5 are basically the same. Train B in Table 5 shows the instances after applying the SMOTE ratios in Table 6. We deﬁne the three classes of U2R, R2L, and Probe as rare classes because the classes have relatively fewer instances than other classes. Label cardinality of D is the average number of labels of the examples in D: LC(D) � imbalance ratioi � 􏼌􏼌􏼌􏼌 􏼌􏼌􏼌􏼌, Yi 1 |D| |D| 􏽘 i�1 􏼌􏼌􏼌􏼌 Yi LC(D)− Yi 􏼌􏼌􏼌􏼌 􏼌􏼌􏼌􏼌 . 􏼌􏼌􏼌􏼌 (1) Figure 1: 1e structure of the dataset used in the proposed method. 4.2. Proposed Method. We attempt to optimize the SMOTE ratios of rare classes to mitigate the class imbalance. It is diﬃcult to test all tuples of SMOTE ratios in a short period of time. 1erefore, we attempt to identify an eﬃcient method with a small number of experiments and reduce computation time. We create an SVR model with a small number of ex- periments and try to get the best tuple of the SMOTE ratios by inputting enough tuples of SMOTE ratios into the model. We also verify the results through experiments. 1e numbers of 100 and 1,000,000, which are used in the experiments, are decided by considering computation time and 100 instances are generated randomly from a uniform distribution. We use random sampling method instead of grid one. If we can use more than 100 instances, grid sampling is not bad, but the method is not appropriate to sample very few instances uniformly. We set the ranges for the rare classes through preliminary experiments, as shown in Table 7. We randomly generate 100 tuples of SMOTE ratios within the maximum ranges of Table 7. We conduct ex- periments by inputting the 100 tuples into an SVM clas- siﬁer. As results, ﬁve recall values are given to each of the 100 tuples. An SVR model is created using the 100 tuples and the root mean square of the recall values. We randomly generate 1,000,000 tuples of SMOTE ratios and input them into the SVR model to derive the optimal solution. We conduct experiments to verify the quality of the best tuple. the proposed method. 1e method shows good performance with very few tests and signiﬁcantly reduces the amount of computations which are required to ﬁnd the best SMOTE ratios. Figure 2 represents its pseudocode. Formula (2) represents procedure of Procedures of the proposed methods as follows: (1) Set the ranges for the rare classes through pre- liminary experiments, as shown in Table 7. 1e ranges were searched by inputting successive 2t where t is a nonnegative integer. (2) Generate randomly few tuples of SMOTE ratios from a uniform distribution (independent variable). (3) After drawing recall metrics by giving the tuples into an SVM classiﬁer, calculate RMS with the metrics (dependent variable). (4) Create an SVR model [4] with the tuples and RMS. (5) Find the best tuple among a lot of tuples, which are generated randomly from a uniform distribution, through the SVR model. KDDdatasetTestTrain ATrain BValidation50%50% 6 Classes Normal U2R R2L DoS Probe Table 5: Class imbalance ratios of Train A, Train B, Validation, and Test dataset. Computational Intelligence and Neuroscience #Train A 97,278 52 1,126 391,458 4,107 Ratio (%) 24.52% 0.01% 0.23% 381.68% 0.84% #Train B 48,639 26,026 254,476 195,729 4,108 Ratio (%) 10.13% 5.17% 92.70% 58.73% 0.78% #Validation 48,639 26 563 195,729 2,053 Ratio (%) 24.52% 0.01% 0.23% 381.68% 0.84% #Test 60,593 39 5,993 223,298 2,377 Ratio (%) 26.15% 0.01% 2.09% 323.61% 0.82% 1e proposed (%) Table 6: Comparison between the proposed SMOTE ratio and the previous one. Classes Normal U2R R2L DoS Probe 12,000 900 — 150 1e previous [5] (%) 100,000 49,500 — 100 — — Table 7: Range of SMOTE ratio for the rare classes. SMOTE ratio 100–100,000% 100–50,000% 100–20,000% U2R R2L Probe // N: normal, U: change to U2R, R: R2L, D: DoS, P: change to Probe, m: the number of classes, // Umax, Rmax, Pmax: maximum range of each class, // Tmodel: tuples of SMOTE ratios required for model creation, // Teval: tuples of SMOTE ratios required to evaluate 􏼃, P⟵ 1, Pmax 􏼂 􏼂 􏼂 the model, // tbest: the best tuple among Teval, 􏼃, R⟵ 1, Rmax U⟵ 1, Umax Tmodel⟵ U, R, P Model⟵ SVR Classifier Tmodel, RMS tbest⟵ arg max Model Teval �������������������������� 2 􏽐m 􏼁 i i�0 SVM Classifier Tmodel RMS � m 􏽳 􏼁. }, 􏼁 􏼁 { (cid:0) (cid:0) (cid:0) (cid:0) (cid:0) 􏼁, , 􏼃, (2) Figure 3 shows a hierarchy of the methods in LibSVM. Table 8 represents the time complexity of SVM. Table 9 shows the time complexity of the proposed methods. 5. Experiments We randomly generate 100 tuples of SMOTE ratios and use the tuples to create an SVR model. We ﬁnd the best tuple by giving 1,000,000 randomly generated tuples of SMOTE ratios into the SVR model. 1e experiment results with the best tuple were improved by approximately 20 percent compared with the previous approach [5]. 1e SVR model was generated using only 100 tuples of SMOTE ratios. As with the SVR model, the computation time was dra- matically reduced and the tuple of SMOTE ratios with the highest eﬃciency was found. Formula (3) gives the root mean square (RMS) using the recall values, which are the results of experiments with the 100 tuples of the SMOTE ratios of the U2R, R2L, and Probe classes. 1e 100 tuples are randomly generated within the range of Table 7. Variable N is the normal, U is the U2R, R is the R2L, D is the DoS, and P is the Probe class. Table 10 shows parameters of SVR and SVM. Table 11 shows pa- rameters of RNN-LSTM. Table 12 shows the measures drawn by creating an SVR model using the 100 tuples of SMOTE ratios and the RMS. 1e correlation coeﬃcient was more than 0.7, which indicates a strong positive linear re- lationship. 1e RMSE was 0.006, which means that the diﬀerence between the expected value and the actual one is very small. Since the root relative squared error is a measure that compares the standard deviation of the actual values with the diﬀerences between the predicted and actual values, it is not a signiﬁcant factor in evaluating the performance of the model. Table 13 shows the recall metrics of experiments by the best tuple. 1e best tuple represents 1,000 times for the U2R, 451 times for the R2L, and 1 time for the Probe, as shown in Table 6. Table 6 shows the diﬀerence of SMOTE ratios between the proposed method and the previous one. 1e proposed method searches an optimal solution among a lot of SMOTE ratios, but the previous one uses only ﬁxed SMOTE ratios. 􏽳 RMS � ������������������������������� N2 recall + D2 recall + U2 recall + R2 recall + P2 recall The number of classes . (3) Figure 4 compares recall metrics of the proposed method with that of the previous approach [5]. RNN-LSTM is slightly superior to other methods. In the SVM tests, the performances of the U2R, R2L, and Probe classes were improved by approximately 22.6%, 58.9%, and 2.3%, re- spectively. Figure 5 represents SMOTE ratios of the U2R, Computational Intelligence and Neuroscience 7 Figure 2: Pseudocode of the proposed method. Figure 3: Hierarchy of the methods in LibSVM [23]. Table 8: Time complexity of the methods in LibSVM [23]. Methods Complexity (Big-O) Worst case Num. 1 2 3 4 5 6 7 8 9 svm_train svm_predict Parse_command_line Read_problem SVM _check_parameter SVM_train SVM_save_model SVM_load_model SVM_check_probability_model SVM_predict_probability SVM_predict O(mn + n2) O(n) O(mn) O(n2m) O(mn) O(mn) O(1) O(n2) O(n3) Table 9: Time complexity of the proposed methods. Num. of the procedures of the proposed methods 1 2 3 4 5 Complexity (Big-O) // g is the number of experiments O(g) // h is the number of 100 tuples which are randomly generated. O(h) O(h) + svm_train + O(h) O(h) + svr_train // 1e time complexity of svr_train is identical to svm_train. // k is the number of 1,000,000 tuples which are randomly // If an algorithm does not depend on n, which is a symbol of amounts of data, then the algorithm has constant complexity or symbolized by O(1) [23]. 1erefore, the time complexity of svr_test is identical to O(1). generated. k∗ svr_test O(n2·m) O(n3) Worst case O(g) O(h) O(n2·h) O(n2·h) O(k) // SMOTE is not applied to Normal and DoS classes// D: preprocessed KDD CUP 1999 dataset// Dtrain: the ﬁrst 50% of D, Dtest: the last 50% of D// Dtrain_b: the ﬁrst 50% of Dtrain, Dvalidation: the last 50% of Dtrain// Srand_1: 100 of randomly generated SMOTE ratios// SRMS: root mean squared values of recall metrics drawn from a test using Dtrain_bwith Srand_1 applied and Dvalidation// SVRmodel: a model created by Srand_1 and SRMS// Srand_2: 1,000,000 of randomly generated SMOTE ratios// O: optimal SMOTE ratio(Dtrain, Dtest) split D into 50:50(Dtrain_b, Dvalidation) split Dtrain into 50:50SRMSroot mean square using Dtrain_b with Srand_1 applied and DvalidationSVRmodelan SVR model created using Srand_1 and SRMSOargmax(SVRmodel(Srand_2))Do experiments using Dtrain with O applied and DtestLibSVMsvm_predictsvm_trainparse_command_lineread_problemsvm_check_parametersvm_trainsvm_save_modelsvm_load_modelsvm_check_probability_modelsvm_predict_probabilitysvm_predict 8 SVR parameters Batch size C Filter type Kernel RegSMOImproved optimizer Parameters Input layers Iteration (hidden layers) Classes Batch size Epochs Learning rate Optimizer Computational Intelligence and Neuroscience Table 10: SVR and SVM parameters. Normalize training data Values 100 1 PolyKernel 1.0E–12 0.001 0.001 SVM parameters Batch size c Filter type Epsilon Calibrator Kernel Tolerance Param. Normalize training data Values 100 1 1.00E–12 Logistic PolyKernel 0.001 Epsilon Epsilon Param. Tolerance Table 11: RNN-LSTM parameters. Values 41 82 5 Full 5000 0.001 RMSProp Table 12: Results of the SVR model (10-fold cross-validation). Measures Correlation coeﬃcient Mean absolute error Root mean squared error Relative absolute error Root relative squared error Standard deviation of SMOTE ratios U2R R2L Probe Table 13: Recall metrics of SVM, decision tree, and RNN-LSTM tests. Train B + Validation Train B + Test Train A + Test Classes Normal U2R R2L DoS Probe SVM 0.961 0.808 0.982 0.999 0.924 DT 0.999 0.769 0.961 1.000 0.992 LSTM 0.967 0.769 0.975 0.999 0.974 SVM 0.977 0.641 0.275 0.855 0.928 DT 0.993 0.462 0.235 0.999 0.988 LSTM 0.947 0.641 0.260 0.998 0.977 SVM 0.977 0.564 0.302 0.871 0.941 DT 0.994 0.256 0.261 0.996 0.997 Values 0.760 0.005 0.006 60.9% 64.6% 292.071 158.932 58.276 LSTM 0.982 0.615 0.274 0.999 0.996 R2L, and Probe used to create the SVR model. Table 14 [22] compares the proposed methods with other work by the detection rate. Figure 6 shows a graph for the RMS of the results obtained by inputting 1,000,000 tuples of SMOTE ratios into the SVR model. 1e reason for deﬁning the RMS of Formula (3) as the objective value is to make the recall values of rare classes well reﬂected by experimental results. An RMS of the best tuple is about 0.979. Table 15 shows recall values of previous work [5]. Tables 16 and 17 show confusion matrix of SVM and RNN-LSTM, respectively. We conducted experiments with SVM and decision tree on the three dataset combi- nations of (Train B, Validation), (Train B, Test), and (Train A, Test) datasets. 1e results showed that SVM was better than the decision tree. Table 16 represents recall values of the previous methods and SVM was superior to other work. Parameters and datasets of is identical to those of the previous one. the proposed SVM test 6. Conclusions In this study, we have attempted to mitigate the problem of class imbalance in the KDD CUP 1999 intrusion detection dataset. As results, we obtained the best SMOTE ratios of rare classes, reduced the number of experiments by creating an SVR model, and had a signiﬁcant performance im- provement over the previous approach [5]. 1e best SMOTE ratios of rare classes drawn by the SVR model were 1,000 times for U2R, 451 times for R2L, and 1 time for Probe. 1e recall values for rare classes were 0.615 for the U2R in RNN- Computational Intelligence and Neuroscience 9 Figure 4: Comparison bar chart of the RNN-LSTM, SVM, decision tree, and previous SVM tests [1]. 1e dotted red lines represent the best recall values among rare classes. (a) (b) Figure 5: SMOTE ratios of the U2R, R2L, and Probe used to create the SVR model (RMS values). (a) U2R vs. R2L. (b) R2L vs. Probe. (c) Probe vs. U2R. (c) 400200200400U2RRMS0.97600.97080.96570.96050.95530.95010.94500.93980.93466008001000R2L150100200R2L400Probe50RMS0.97600.97080.96570.96050.95530.95010.94500.93980.934650100Probe150U2R1000800600400200RMS0.97600.97080.96570.96050.95530.95010.94500.93980.93460.9820.6150.2740.9990.9960.9770.5640.3020.8710.9410.9940.2560.2610.9960.9970.9900.4600.1900.8700.9200.10.20.30.40.50.60.70.80.91.0NormalU2RR2LDoSProbeLSTMSVM (poly)Decision treePrevious (SVM)RMS 10 Computational Intelligence and Neuroscience SVM LSTM 1ese methods SVM and clustering [22] ESC-IDS [24] KDD’99 winner [25] KDD’99 runner-up [26] Multiclassiﬁer [27] Association rule [28] Normal Table 14: Comparisons with other works by detection rate. DoS 87.1 99.9 99.5 99.5 97.1 97.5 97.3 96.8 U2R 56.4 61.5 19.7 14.1 13.2 11.8 29.8 3.8 R2L 30.2 27.4 28.8 31.5 8.4 7.3 9.6 7.9 97.7 98.2 99.3 98.2 99.5 99.4 N/A 99.5 Probe 94.1 99.6 97.5 84.1 83.3 84.5 88.7 74.9 Acc. 88.2 98.1 95.7 95.3 91.8 91.5 N/A N/A FP 2.4 0.4 0.7 1.9 0.6 0.6 N/A N/A Figure 6: Bar chart representing RMS for 1,000,000 tuples of SMOTE ratios which are randomly generated. 1e red dots represent SMOTE ratios with high RMS value. Table 15: Recall metrics of previous work [5]. Table 17: Confusion matrix of RNN-LSTM. Classes Normal U2R R2L DoS Probe SVM 0.990 0.460 0.190 0.870 0.920 k-NN 1.000 0.440 0.140 1.000 0.830 Decision tree 1.000 0.280 0.130 1.000 1.000 Actual class Normal U2R R2L DoS Probe Predicted class Normal U2R R2L 59,528 657 10 1640 4 4,316 20 4 92 24 23 0 0 2 0 DoS 86 0 12 223,169 6 Probe 230 1 2 107 2,367 Table 16: Confusion matrix of SVM. Predicted class Actual class Normal U2R R2L DoS Probe Normal U2R R2L 249 59,196 14 1,810 3 4,074 28,759 127 299 22 106 0 0 4 11 DoS 683 0 2 194,517 3 the number of adjustments for classes. 1erefore, the computation time required for the experiments could be shortened. In future, it will be meaningful to investigate the change of test results according to the number of tuples of SMOTE ratios. We can identify better SMOTE ratios using the models created by other machine-learning techniques. Also, we will apply evolutionary computations or other meta- heuristic algorithms to identify the best tuple. Probe 166 0 1 18 2,236 LSTM, 0.302 for the R2L in SVM, and 0.997 for the Probe in decision tree, respectively. We proposed a new method to ﬁnd the best SMOTE ratios that have high eﬃciency with a small number of experiments. 1e proposed method dramatically reduced Data Availability 1e KDD CUP 1999 data used to support the ﬁndings of this study are available at http://kdd.ics.uci.edu/databases/ kddcup99/kddcup99.html. 0.000.977800.978000.978200.978400.978600.978670.978650.97865RMS100000.00200000.00300000.00400000.00500000.00# SMOTE ratios600000.00700000.00800000.00900000.001000000 Computational Intelligence and Neuroscience 11 Conflicts of Interest 1e authors declare that they have no conﬂicts of interest. Acknowledgments 1is research was supported by Wonkwang University in 2017. References [1] Intrusion Detection System, 2018, https://en.wikipedia.org/ wiki/Intrusion_detection_system. to [2] R. C. Staudemeyer, “Applying long short-term memory recurrent detection,” South African Computer Journal, vol. 56, no. 1, pp. 136–154, 2015. intrusion networks neural [3] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Jour- nal of Artiﬁcial Intelligence Research, vol. 16, pp. 321–357, 2002. [4] A. J. Smola and B. Sch¨olkopf, “A tutorial on support vector regression,” Statistics and computing, vol. 14, no. 3, pp. 199– 222, 2004. [5] J. H. Seo, “A study on the performance evaluation of un- balanced intrusion detection dataset classiﬁcation based on machine learning,” Journal of the Korean Institute of In- telligence Systems, vol. 27, no. 5, pp. 466–474, 2017. [6] S. J. Stolfo, “KDD cup 1999 dataset, UCI KDD Repository,” 1999, http://kdd.ics.uci.edu. [7] K. Leung and C. Leckie, “Unsupervised anomaly detection in network intrusion detection using clusters,” in Pro- ceedings of Twenty-Eighth Australasian Computer Science Conference, vol. 38, pp. 333–342, Newcastle, Australia, January 2005. [8] Y. X. Meng, “1e practice on using machine learning for network anomaly intrusion detection,” in Proceedings of International Conference on Machine Learning and Cy- bernetics, vol. 2, pp. 576–581, IEEE, Guilin, China, July 2011. [9] M. A. Hearst, S. T. Dumais, E. Osuna, J. Platt, and B. Scholkopf, “Support vector machines,” IEEE Intelligent Systems and their Applications, vol. 13, no. 4, pp. 18–28, 1998. [10] J. J. Davis and A. J. Clark, “Data preprocessing for anomaly based network intrusion detection: a review,” Computers & Security, vol. 30, no. 6-7, pp. 353–375, 2011. [11] R. C. Staudemeyer and C. W. Omlin, “Evaluating perfor- mance of long short-term memory recurrent neural networks on intrusion detection data,” in Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference on—SAICSIT’13, pp. 218–224, ACM Press, London, October 2013. [12] G. Kim, H. Yi, J. Lee, Y. Paek, and S. Yoon, “LSTM-based system-call language modeling and robust ensemble method for designing host-based intrusion detection systems,” 2016, http://arxiv.org/abs/1611.01726. [13] J. Kim, N. Shin, S. Y. Jo, and S. H. Kim, “Method of intrusion detection using deep neural network,” in Proceedings of IEEE International Conference on Big Data and Smart Computing, pp. 313–316, IEEE, Jeju-do, South Korea, February 2017. [14] T. T. H. Le, J. Kim, and H. Kim, “An eﬀective intrusion detection classiﬁer using long short-term memory with gra- dient descent optimization,” in Proceedings of International Conference on Platform Technology and Service (PlatCon), pp. 1–6, Busan, South Korea, September 2017. [15] N. Japkowicz, “1e class imbalance problem: signiﬁcance and strategies,” in Proceedings of the 2000 International Conference on Artiﬁcial Intelligence, pp. 111–117, 2000. [16] N. Japkowicz and S. Stephen, “1e class imbalance problem: a systematic study,” Intelligent Data Analysis, vol. 6, pp. 429–449, 2002. [17] N. Chawla, A. Lazarevic, L. Hall, and K. Bowyer, “SMOTE- Boost: Improving prediction of the minority class in boosting, Knowledge Discovery in Databases: PKDD,” in Proceedings of European Conference on Principles of Data Mining and Knowledge Discovery, pp. 107–119, 2003. [18] C. Drummond and R. C. Holte, “C4.5, class imbalance, and cost sensitivity: why under-sampling beats over-sampling,” in Proceedings of Workshop on Learning from Imbalanced Datasets II, pp. 1–8, Washington DC, 2003. [19] Z. H. Zhou and X. Y. Liu, “Training cost-sensitive neural networks with methods addressing the class imbalance problem,” IEEE Transactions on Knowledge and Data Engi- neering, vol. 18, no. 1, pp. 63–77, 2006. [20] J. Burez and D. Van den Poel, “Handling class imbalance in customer churn prediction,” Expert Systems with Applications, vol. 36, no. 3, pp. 4626–4636, 2009. [21] C. Seiﬀert, T. M. Khoshgoftaar, J. Van Hulse, and A. Napolitano, “RUSBoost: a hybrid approach to alleviating class imbalance,” IEEE Transactions on Systems, Man, and Cybernetics—Part A: Systems and Humans, vol. 40, no. 1, pp. 185–197, 2010. [22] S. J. Horng, M. Y. Su, Y. H. Chen et al., “A novel intrusion detection system based on hierarchical clustering and support vector machines,” Expert systems with Applications, vol. 38, no. 1, pp. 306–313, 2011. [23] A. Abdiansah and R. Wardoyo, “Time complexity analysis of support vector machines (SVM) in LibSVM,” International Journal Computer Application, vol. 128, no. 3, pp. 28–34, 2015. [24] A. N. Toosi and M. Kahani, “A new approach to intrusion detection based on an evolutionary soft computing model using neuro-fuzzy classiﬁers,” Computer Communications, vol. 30, no. 10, pp. 2201–2212, 2007. [25] B. Pfahringer, “Winning the KDD99 classiﬁcation cup: bag- ged boosting,” ACM SIGKDD Explorations Newsletter, vol. 1, no. 2, pp. 65-66, 2000. [26] I. Levin, “KDD-99 classiﬁer learning contest: LLSoft’s results overview,” ACM SIGKDD Explorations, vol. 1, no. 2, pp. 67–75, 2000. [27] M. R. Sabhnani and G. Serpen, “Application of machine learning algorithms to KDD intrusion detection dataset with in misuse detection context,” in Proceedings of the In- ternational Conference on Machine Learning: Models, Tech- nologies, and Applications, pp. 209–215, Las Vegas, NV, USA, June 2003. [28] W. Xuren, H. Famei, and X. Rongsheng, “Modeling intrusion detection system by discovering association rule in rough set theory framework,” in Proceedings of International Conference on Computational Intelligence for Modelling, Control and Automation, 2006 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce, p. 24, Vienna, Austria, November-December 2006. Applied Computational Intelligence and Soft Computing Hindawi www.hindawi.com Volume 2018 Modelling & Simulation in Engineering Hindawi www.hindawi.com Volume 2018 International Journal of Reconﬁgurable Computing Advances in Multimedia Mathematical Problems in Engineering Journal of Engineering Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 The Scientific World Journal Hindawi Publishing Corporation Hindawi http://www.hindawi.com www.hindawi.com Volume 2013 Volume 2018 Advances in Artificial Intelligence Hindawi www.hindawi.com Volume 2018 Advances in Fuzzy Systems Submit your manuscripts at www.hindawi.com Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Scienti(cid:24)c Programming Advances in Human-Computer Interaction International Journal of Engineering Mathematics Advances in Civil Engineering Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Journal of Computer Networks and Communications Hindawi www.hindawi.com Volume 2018 International Journal of Biomedical Imaging Journal of Robotics Hindawi www.hindawi.com International Journal of Computer Games Technology Journal of Electrical and Computer Engineering Computational Intelligence and Neuroscience Volume 2018 Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Hindawi www.hindawi.com Volume 2018 Copyright of Computational Intelligence & Neuroscience is the property of Hindawi Limited and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use.