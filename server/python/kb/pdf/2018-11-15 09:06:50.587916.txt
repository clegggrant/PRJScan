Research ArticleA Deep Learning Approach to Vascular Structure Segmentationin Dermoscopy Colour ImagesJoanna Jaworek-KorjakowskaDepartment of Automatic Control and Robotics, AGH University of Science and Technology, Cracow, PolandCorrespondence should be addressed to Joanna Jaworek-Korjakowska; jaworek@agh.edu.plReceived 2 July 2018; Revised 3 October 2018; Accepted 14 October 2018; Published 1 November 2018Gu est Editor: Fabien ScalzoCopyright © 2018 Joanna Jaworek-Korjakowska. This is an open accessarticledistributed under the CreativeCommons AttributionLicense,whichpermitsunrestricteduse,distribution,andreproductioninanymedium,provided theoriginal work isproperly cited.Background. Atypical vascular pattern is one of the most important features by differentiating between benign and malignantpigmented skin lesions. Detection and analysis of vascular structures is a necessary initial step for skin mole assessment; it is aprerequisitesteptoprovideanaccurateoutcomeforthewidelyused7-pointchecklistdiagnosticalgorithm.Methods.Inthisresearchwe present a fully automated machine learning approach for segmenting vascular structures in dermoscopy colour images. The U-Net architecture is based on convolutional networks and designed for fast and precise segmentation of images. After preprocessingthe images are randomly divided into 146516 patches of64×64pixels each.Results. On the independent validation datasetincluding 74 images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network,an average DSC of 0.84, sensitivity 0.85, and specificity 0.81 has been achieved.Conclusion. Vascular structures due to small sizeand similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use ofadvanced segmentation methods like deep learning, especially convolutional neural networks, has the potential to improve theaccuracy of advanced local structure detection.1. IntroductionMelanoma is the deadliest form of skin cancer which devel-ops when skin cells multiply rapidly as a consequence ofmutations in their DNA caused by the sun’s ultraviolet (UV)radiation (Figure 1). Melanoma is a cancer that starts in themelanocytes which are cells that make a brown pigmentcalled melanin, which gives the skin its tan or brown colour[1]. Other names for this cancer include malignant melanomaand cutaneous melanoma. Most melanoma cells still makemelanin, so melanoma tumours are usually brown or blackbut can appear pink, tan, or even white [1]. The introductionof dermoscopy has improved the accuracy of diagnosis ofmelanoma.According to the World Health Organization about132,000 new cases of malignant melanoma are diagnosedworldwide each year. In some parts of the world, especiallyin New Zealand and Australia, melanoma is becoming morecommon every year and has more than doubled in the past30 years [2]. For 2018 it is predicted that 14,320 new cases ofmelanoma skin cancer will be diagnosed in Australia whichis estimated to be 10,4% of all new diagnosed cancer cases [3].One of the main goals in prevention of malignantmelanoma is awareness, early diagnosis and surgical excision.The introduction of dermoscopy has improved the accuracyof diagnosis of melanoma. Digital dermoscopy is currentlythe most used technology, although novel methods, suchas confocal microscopy, show promising result. Nowadays,dermatologists work in order to define the different skinlesion types based on dermatoscopic features to improve earlydetection (Figure 2) [4].1.1. Motivation.Recently, the most commonly used diagnos-tic method is the 7-point checklist algorithm. The 7-pointchecklist is a diagnostic method that requires the identifica-tion of only 7 dermoscopic criteria, thus enabling even lessexperienced clinicians to perform the skin mole examination.One of the most important dermoscopic criteria is theatypical vascular pattern which has the second highest oddsratio of 7.42 and is among the 3 most important features thatHindawiBioMed Research InternationalVolume 2018, Article ID 5049390, 8 pageshttps://doi.org/10.1155/2018/50493902BioMed Research International(a)(b)(c)Figure 1: Melanocytic lesion analysis is one of the most difficult areas in modern dermatology. The challenges fall into two broad categories,namely, the recognition of rare but characteristic entities and the much more common problem of where to place an unusual lesion on thespectrum of melanocytic lesions. Examples of melanocytic lesions: (a) melanoma in situ, (b) dermal nevus, Unna type, and (c) early invasivemelanoma.DERMOSCOPYFigure 2: Examination of pigment mole with a dermatoscope.Diag-nostic instrument commonly used for dermoscopic examination is ahand-held dermatoscope. Dermoscopy is a noninvasive method thatallows evaluation of colours and microstructures of the epidermis,the dermoepidermal junction, and the papillary dermis not visibleto the naked eye.indicate the malignancy of the skin mole. Atypical vascularpattern appears as linear-irregular or dotted vessels notclearly combined with regression structures and associatedwith other local structures [6, 7]. Dermoscopy images showonly the horizontal inspection of the skin lesion. Vascularstructures that are located in parallel to the skin’s surfacewill appear as a line, while those located vertically to theskin’s surface will become visible as dots and nodes. In thisrespect, we observe a strong connection between the vascularstructure and tumour progression and volume. Flat andsuperficial amelanotic/hypomelanotic melanoma and basalcell carcinoma will display different vascular structures thanthose of their thick or nodular counterparts (Figure 3) [8].Based on the information above exact detection andclassificationofvascularstructuresisacrucialstepinearlyand accurate diagnosis of malignant melanoma. In this paperwe present a new and of the first approaches to the detectionof vessels in dermoscopic colour images. In this study, deeplearning methods (CNNs) have been used to fully automati-cally localize and segment vascular structure. To evaluate theperformance of deep learning segmentation, we comparedthe outcome with the manual segmentation. Deep learningtechnologies have the potential to improve the accuracy andspeed up the diagnosis of skin structure in clinical settings.1.2. Related Works.Tothebestofourknowledgeonlyfewattempts have been made to detect vascular structures indermoscopic colour images. Recently, Kharazmi et al. in work[9] proposed a data-driven feature learning framework basedon stacked sparse autoencoders (SSAE) for comprehensivedetection of cutaneous vessels. The proposed frameworkdemonstrated performance of 95.4% detection accuracy overa variety of vessel patterns. Betta et al. in work [10] presenteda method for the identification of atypical vessels. Due tothe difficulty to obtain a relevant number of epilumines-cence microscopy (ELM) images with the occurrence of thislocal structure, the training set was constituted by pixelsselected as vascular pattern in a set of images containingoccurrences of this criterion. The Hue, Saturation, andLuminance components were evaluated and the frequencyhistograms corresponding to the three colour planes weredetermined. The pixel classification depended on the valueof the particular HSL component. However, the authorswarned that in some cases the algorithm misclassified thearea, evidencing a low specificity [4, 11]. In 2014, Fabbrociniet al. proposed an automatic detection algorithm combin-ing colour segmentation and structural analysis [12]. Theskin lesion area was matched with the texture descriptors(entropy, inverse difference moment, and correlation) basedon the gray level cooccurrence matrix in order to excludetexture areas. Then, a statistical analysis of the segmentswas performed. The system has been tested on 200 medicalimages and achieved 80% sensitivity, and 78% specificity.More recently Kharazmi et al. [13] proposed a new approachto vessel segmentation. Authors firstly decompose the imageusing independent component analysis into melanin andhemoglobin. Using k-means clustering, the hemoglobin com-ponent is clustered and a vessel mask is generated as a resultof global thresholding. The segmentation sensitivity andspecificity of 90% and 86% were achieved on a set of 500 000manually segmented pixels provided by an expert. Recently,advances have been observed in retinal vessel segmentation,which is another medical area, where vessel segmentation iscrucial for accurate diagnosis and early treatment. In [14]authors present the implementation of the neural networkstructure derived from the U-Net architecture. The algorithmobtained an AUC-ROC accuracy of 0.98.2. Material and MethodsArtificial intelligence research has been around for more thanhalf a century but in recent years a huge progress is observedBioMed Research International3(a)(b)(c)Figure 3: Examples of vascular patterns that can be identified in melanocytic lesions: (a) polymorphous vessels: different vascularmorphologies in the same mole, (b) dotted vessels: small, reddish vessels that resemble a pinhead, and (c) arborizing vessels: large vesselsthat branch into finer, small vessels [5].in widely understood machine learning [15]. Advanced sta-tistical techniques, known as deep learning models, havebeen exploited with impressive results. Convolutional neuralnetworks applied in this research learn feature representationautomatically from the training data [16]. Deep learning ingeneral and convolutional neural networks in particular havebeen used in variety of pattern recognition problems likeretinal vessel segmentation, lung area detection, or breastcancer classification [17].2.1. Overview.As illustrated in Figure 4 the implementedapplication is divided into four stages: preprocessing (imageenhancement),  patch  extraction,  training,  and  valida-tion.In this research we use the U-Net convolutional networkarchitecture introduced by Ronneberger et al. in 2015 [18].This method was chosen because it is one of the mostpromising for the addressed problem, especially, advancedimage segmentation. In this section, the preprocessing stepis described shortly, based on previous works, while the net-work architecture and training phase are presented in detail.The preprocessing and patch extraction stages have beenimplemented in Matlab 2017a while the neural architectureand classification process has been performed in Pythonusing U-Net implementation as proposed by Ronnebergeretal.and developed with TensorFlow [18, 19].2.2. Image Preprocessing.The first step in every medicalimage processing system is the image acquisition, which aimsat obtaining an image of the highest quality. After dermo-scopic image is acquired, it may not have the expected qualityto perform the diagnostic analysis. Dermoscopic imagesare inhomogeneous and complex and furthermore includeextraneous artifacts, such as skin lines, air bubbles, and hairs,which appear in virtually every image. The preprocessingstage consists of two parts. The first step is the removalof black frame that is introduced during the digitizationprocess. The second step is a hair-removal algorithm whichcomprises two parts: hair detection and inpainting. Thesesteps have been precisely described in our previous works[20, 21].2.3.  Patches Extraction.After preprocessing we extract푁small patches푥푚,푛of size64×64from the dermoscopy image퐼and the corresponding annotation퐺at the same position.The so-called ground-truth mask contains zeros and ones,where(푥푖,푦푗)=1informs that there is a vessel area at thislocation. Patch extraction can be performed in few differentways: nonoverlapping, overlapping, and randomly extracted.Each of these solutions has its advantages and disadvantages.To avoid the problem of class imbalance, patches have beenextracted randomly around pixels pointing to vessel area bothfrom dermoscopy image as well as from the accompanyingmasks. For 74 dermoscopy images with different resolutionwe have obtained 146516 patches. The size of the patches hasbeen chosen experimentally and concatenated with the U-Net architecture. Larger patches require more max-poolinglayers that reduce the localization accuracy, while smallpatches allow the network to see only little context [18].2.4. Network Architecture.U-Net convolutional network isa popular architecture in the class of encoder-decoders,where the encoder reduces the spatial dimension of objectswith pooling layers while decoder recovers the object detailswith upsampling layers. U-Net is a modified and extendedversion of fully convolutional network. Figure 5 presents theoverview of a U-Net architecture.U-Net consists of contracting path (left side) and anexpansive path (right side). U-Net is like a combination ofconvolutional and deconvolution layers. Contracting pathstructurally repeats a typical3×3convolutional layer(unpadded convolutions) followed by a Rectified Linear Unitand a2×2max-pooling operation with stride 2 for down-sampling. On the expansive path, information is merged from4BioMed Research InternationalImage ProcessingInput imageFrame removalHair removalOutput imageInput imagePatches (64x64)Patches ExtractionTrainingInput imageInput images (patches)U-NetMax-poolingUpsamplingConcatVessel segmentationSoftmaxFigure 4: Illustration of the proposed system. (a) Image preprocessing involves black frame, hair and air bubble detection, removal orinpainting, and furthermore image normalization. (b) Patch extraction is carried out in a randomly sliding window with some overlap.(c) U-Net architecture construction and neural network training.layers of contracting path of appropriate resolution and layersof expansive path of lower resolution, so that a whole networkrecognizes patterns at several scales. The final layer of a1×1convolution is used to map each 64-component featurevectors to the desired number of classes [18]. Input imageis firstly passed through a convolutional layer with RectifiedLiner Unit (ReLu) activation function:푓(푥)=max(0,푥)(1)The rectifier is an activation function defined as the positivepart of its argument where푥is the input to a neuron. Ourfirst layer has 64-feature map. Afterwards the max-poolingoperation is applied. The convolutional layers downsamplethe spatial dimension from64×64to8×8.Theexpansivepath consists of an upsampling of the feature map followedby upconvolutional and convolution layers with ReLU [17]. Aswe have only 2 classes (present or absent) we use the softmaxclassifier that calculates the cross-entropy loss for every singleexample:퐿푖=−log(푒푓푦푖∑푗푒푓푗)(2)The encoder and decoder comprise five layers with (64 - 128-256-512-1024)and(1024-512-256-128-64)filtersofsize (3푥3) pixels, respectively. We have chosen the Adamoptimization algorithm that is an extension to stochasticgradient descent that has recently seen broader adoption fordeep learning applications in computer vision and naturallanguage processing.3. Results3.1. Image Database.The proposed segmentation methodbased on the U-Net neural network architecture has beentested on colour dermoscopic images from a widely usedInteractive Atlas of Dermoscopy [6]. Images for this repos-itory have been provided by two university hospitals (Uni-versity of Naples, Italy, and University of Graz, Austria)and stored on a CD-ROM in the JPEG format. The docu-mentation of each dermoscopic image was performed usinga Dermaphot apparatus (Heine, Optotechnik, Herrsching,Germany) and a photo camera (Nikon F3) mounted on astereomicroscope (Wild M650, Heerbrugg AG, Switzerland)in order to produce digitized ELM images of skin lesions. Allthe images have been assessed manually by a dermoscopicexpert with an extensive clinical experience. Additionally,colour images have been used from the푃퐻2database [22],and images available in online libraries [23, 24]. The databaseBioMed Research International5Input images (patches)Max-poolingUpsamplingConcatSoftmax6464 64128 128128128256 256256256512512512 51210241024Figure 5: Original layers of U-Net: an encoder-decoder architecture. Each box corresponds to a multichannel feature map. The horizontalarrow denotes transfer residual information form early stage to later stage.(a)(b)(c)Figure 6: Database examples.included 74 cases with different types of vascular patternincluding linear, dotted, comma, hairpin, and polymorphous.Dermoscopy colour images have different resolutions, rang-ing from 0.033 to 0.5mm/pixels. Figure 6 presents samplesfrom our database.3.2. Deep Network (CNN) Training.The database set wasdivided into training set (80%) and test set (20%). Thetraining set was used for train the U-Net, while the testset was used to analyse the training versus test error incase of overfitting. In the training stage the input image(patch) and the corresponding ground-truth mask are usedto train the implemented U-Net network. The softmax layerat the end of the network creates a probabilistic two-channeloutput, just like a binary segmentation problem. However,the ground truth here is a probabilistic map, not a binarysegmentation map. Training is performed for 100 epochs.As training continuous (seen by epoch) we can see that thegenerated mask becomes more precise (Figure 7). Grayscaleimages in Figure 7 present predictions as a grayscale map,where light colours display values near 1, while dark coloursdisplay values near 0.For the U-Net architecture the patch-size, the batch-size,and the weighted pixel-wise cross entropy were proved to beof high importance. The patch-size proved to be best at64×64pixels with a large batch-size. When the batch-size is too low,6BioMed Research International(a)(b)(c)Figure 7: Visualization of segmentation precision over 100 epochs. Colour vascular structures in training patch slices (left), accompanyingground-truth masks (middle), and the predictions (right): (a) 10 epochs, (b) 76 epochs, and (c) 95 epochs.Figure 8: Examples of the incorrect segmentation of vascular structures. Different unmarked vascular patterns are still visible.it might be unable to learn, thus negatively impacting totalcomputation time. The predictions were thresholded at 0.5andaredisplayedasabinarymasks(Figure8).3.3. Analysis of CNN Segmentation Method.The performanceof the U-Net neural network vascular structure segmentationapproach can be assessed based on the analysis ofSørensenindexalso known asdice similarity coefficientwhich is astatistic used for comparing the similarity of two samples[25].Given two binary sets,푋and푌,theSørensen’sformulaisdefined as퐷푆퐶=2|푋∩푌||푋|+|푌|(3)Using the definition of true positive (TP), false positive (FP),and false negative (FN), it can be written as퐷푆퐶=2푇푃2푇푃+퐹푃+퐹푁(4)where TP denotes vascular structure pixels, FP denotes vas-cular structure pixels not detected, FP denotes backgroundpixels classified as vascular structures.The DSC is a statistical measure that calculates the degreeof overlapping between the experimental segmentation andthe manual segmentation and is frequently used to comparesegmentations.Furthermore, sensitivity and specificity are calculatedusing following equation:푆퐸=푇푃푇푃+퐹푁(5)푆푃=푇푁푇푁+퐹푃(6)The proposed algorithm achieved an average DSC of 0.84,sensitivity 0.85, and specificity 0.81. Possible values of DSCrange from 0.0 to 1.0. A perfect classifier or segmentationmodel achieves a DSC of 1.0. The mean DSC scored 0.84in range of 0.54-0.92. Taking into account the fact thatthe vascular structures have been segmented manually forthe ground-truth mask the achieved DSC score is verypromising. We observed that the algorithm misclassifiedareas which were on the boarder between skin lesion andvascular structures as well as the red surrounding betweenskin mole and healthy skin (Figure 8).Figure 9 presents few segmentation results with corre-sponding ground-truth masks and the predictions of the pre-viously unseen test data. The figure contains three columns.From the left to the right, each one represents the originalimage, the ground-truth, and the segmentation result usingthe generated map, respectively. Ground-truth masks andpredictions have been inverted, where white represents vesseltissue and black nonvessel tissue.SectionRelated Workspresented the state of the art ofprevious studies concerning the segmentation of vascularpatterns in dermoscopy images. In paper [13] authors pre-sented a method that achieved sensitivity and specificity of90% and 86%. However, it is difficult to compare these resultsBioMed Research International7(a)(b)(c)Figure 9: Example of dermoscopy images, accompanying segmentation masks and the predictions.because our method has been tested on a much broaderdatabase with more complex images. For the evaluation of theadvantages and correctness of the implemented algorithm,we present several outcomes with segmented structures(Figure 9).4. ConclusionsIn this research we have obtained accurate and compre-hensive results showing that the applying of U-Net neuralnetworks for local structure detection in dermoscopy colourimages brings a valuable alternative to vascular structuredetection. We believe that this solution can be implementedas part of a vascular pattern classification algorithm orfurthermore a computer-aided diagnostic system for earlydetection of melanoma. Our technique shows a clear advan-tage over other implemented and stated in the related workssection algorithms including detection accuracy, insensitiveto different dermoscopy image acquisition methods.4.1. Discussion.Starting from the described framework, fur-ther research efforts will be firstly addressed to compare andintegrate the very promising approaches reported in the mostrecent literature, in order to improve the neural networkand optimize layers and parameters. We will also conducta follow-up study after collecting more data with differentvascular patterns. Future research will concentrate on thepossibility of vascular structure classification.Data AvailabilityPreviously reported dermoscopy images were used to supportthis study and are available at 10.1016/j.jaad.2003.07.029. Theseprior studies (and datasets) are cited at relevant places withinthe text as [6].Conflicts of InterestThe authors declare no conflicts of interest.AcknowledgmentsThis scientific work was financially supported by AGH Uni-versity of Science and Technology Status Funds on Decisionno. 11.11.120.714.8BioMed Research InternationalReferences[1] The American Cancer Society medical and editorial contentteam, “What is melanoma skin cancer?” 2016, https://www.cancer.org/cancer/melanoma-skin-cancer.[2] AIM At Melanoma Foundation, “Understanding melanoma:About  melanoma,” 2017,  https://www.aimatmelanoma.org/about-melanoma/melanoma-stats-facts-and-figures/.[3] Australian Institute of Health and Welfare, “Melanoma of theskin,” 2017, www.aihw.gov.au/acim-books.[4] M. E. Celebi, J. S. Marques, and T. Mendonca,DermoscopyImage Analysis, CRC Press LLC, 1st edition, 2016.[5] J. Mart ́ın, R. Bella-Navarro, and E. Jord ́a, “Vascular Patterns inDermoscopy,”Actas Dermo-Sifiliogr ́aficas (English Edition),vol.103,no.5,pp.357–375,2012.[6] G. Argenziano, P. H. Soyer, V. D. Giorgio et al.,Interactive Atlasof Dermoscopy, Edra Medical Publishing and New Media, 2000.[7] R. Marks, “Epidemiology of melanoma,”Clinical and Experi-mental Dermatology,vol.25,no.6,pp.459–463,2000.[8] E.Ayhan,D.Ucmak,andZ.M.Akkurt,“Vascularstructuresindermoscopy,”Anais Brasileiros de Dermatologia,vol.90,no.4,pp. 545–553, 2015.[9] P. Kharazmi, J. Zheng, H. Lui, Z. Jane Wang, and T. K. Lee, “AComputer-Aided Decision Support System for Detection andLocalization of Cutaneous Vasculature in Dermoscopy ImagesVia Deep Feature Learning,”Journal of Medical Systems,vol.42,no.2,2018.[10] G. Betta, G. Di Leo, G. Fabbrocini, A. Paolillo, and P. Sommella,“Dermoscopic image-analysis system: Estimation of atypicalpigment network and atypical vascular pattern,” inProceedingsof the IEEE International Workshop on Medical Measurementand Applications, MeMeA 2006, pp. 63–67, Italy, April 2006.[11] M.EmreCelebi,W.V.Stoecker,andR.H.Moss,“Advancesinskin cancer image analysis,”Computerized Medical Imaging andGraphics,vol.35,no.2,pp.83-84,2011.[12] G. Fabbrocini, V. D. Vita, S. Cacciapuoti et al., “Automaticdiagnosis of melanoma based on the 7-point checklist,” inComputer Vision Techniques for the Diagnosis of Skin Cancer,J.Scharcanski and M. E. Celebi, Eds., Series in BioEngineering,pp. 71–107, Springer, Berlin, Heidelberg, 2014.[13] P. Kharazmi, M. I. Aljasser, H. Lui, Z. J. Wang, and T. K. Lee,“AutomatedDetectionand Segmentation of VascularStructuresof Skin Lesions Seen in Dermoscopy, with an Application toBasal Cell Carcinoma Classification,”IEEE Journal of Biomed-ical and Health Informatics, vol. 21, no. 6, pp. 1675–1684, 2017.[14] D. Cortinovis,Retina blood vessel segmentation with a convolu-tion neural network (U-net), 2016, https://github.com/qtim-lab/retinaunet.[15] L.Ogiela,R.Tadeusiewicz,andM.R.Ogiela,“Cognitivecom-puting in intelligent medical pattern recognition systems,”Lecture Notes in Control and Information Sciences,vol.344,pp.851–856, 2006.[16] S. Trebeschi, J. J. M. Van Griethuysen, D. M. J. Lambregts etal., “Deep Learning for Fully-Automated Localization and Seg-mentation of Rectal Cancer on Multiparametric MR,”ScientificReports,vol.7,no.1,2017.[17] B.AitSkourt,A.ElHassani,andA.Majda,“LungCTImageSeg-mentation Using Deep Neural Networks,”Procedia ComputerScience,vol.127,pp.109–113,2018.[18] O. Ronneberger, P. Fischer, and T. Brox, “U-net: convolutionalnetworks for biomedical image segmentation,” inProceedings ofthe International Conference on Medical Image Computing andComputer-Assisted Intervention and Medical Image Computingand Computer-Assisted Intervention (MICCAI ’15),vol.9351ofLecture Notes in Computer Science, pp. 234–241, November 2015.[19] J. Akeret, C. Chang, A. Lucchi, and A. Refregier, “Radio fre-quency interferencemitigation using deep convolutional neuralnetworks,”Astronomy and Computing,vol.18,pp.35–39,2017.[20] J. Jaworek-Korjakowska and P. Kłeczek, “Automatic classifica-tion of specific melanocytic lesions using artificial intelligence,”BioMed Research International,vol.2016,ArticleID8934242,17pages, 2016.[21] J.  Jaworek-Korjakowska,  “Computer-aided  diagnosis  ofmicro-malignant melanoma lesions applying support vectormachines,”BioMed Research International,vol.2016,ArticleID4381972, 8 pages, 2016.[22] T. Mendonca, P. M. Ferreira, J. S. Marques, A. R. S. Marcal, andJ. Rozeira, “PH2 - A dermoscopic image database for researchand benchmarking,” inProceedings of the 2013 35th AnnualInternational Conference of the IEEE Engineering in Medicineand Biology Society, EMBC 2013,pp.5437–5440,Japan,July2013.[23] The Skin Cancer Society of Australia, “Dermoscopy atlas,” 2007,http://www.dermoscopyatlas.com/.[24] E. Ehrsam,Dermoscopy, 2016, http://dermoscopic.blogspot.com.[25] T. Sorensen, “A method of establishing groups of equal ampli-tude in plant sociology based on similarity of species and itsapplication to analyses of the vegetation on Danish commons,”Kongelige Danske Videnskabernes Selskab,vol.5,pp.1–34,1948.Hindawiwww.hindawi.com International Journal ofVolume 2018ZoologyHindawiwww.hindawi.comVolume 2018 Anatomy Research InternationalPeptidesInternational Journal ofHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Journal of Parasitology ResearchGenomicsInternational Journal ofHindawiwww.hindawi.comVolume 2018Hindawi Publishing Corporation http://www.hindawi.comVolume 2013Hindawiwww.hindawi.comThe Scientific World JournalVolume 2018Hindawiwww.hindawi.comVolume 2018BioinformaticsAdvances inMarine BiologyJournal ofHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Neuroscience JournalHindawiwww.hindawi.comVolume 2018BioMed Research InternationalCell BiologyInternational Journal ofHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Biochemistry Research InternationalArchaeaHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Genetics Research InternationalHindawiwww.hindawi.comVolume 2018Advance s inVirolog yStem Cells InternationalHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Enzyme ResearchHindawiwww.hindawi.comVolume 2018International Journal ofMicrobiologyHindawiwww.hindawi.comNucleic AcidsJournal ofVolume 2018Submit your manuscripts atwww.hindawi.comCopyrightofBioMedResearchInternationalisthepropertyofHindawiLimitedanditscontentmaynotbecopiedoremailedtomultiplesitesorpostedtoalistservwithoutthecopyrightholder'sexpresswrittenpermission.However,usersmayprint,download,oremailarticlesforindividualuse.