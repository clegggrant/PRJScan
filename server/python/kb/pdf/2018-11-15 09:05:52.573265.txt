RESEARCHARTICLEAnnotationofenhancedradiographsformedicalimageretrievalwithdeepconvolutionalneuralnetworksObiomaPelkaID1,2, FelixNensa3, ChristophM.FriedrichID1,4*1Departmentof ComputerScience,Universityof AppliedSciencesandArtsDortmund(FHDO),Dortmund,NRWGermany,2Facultyof Medicine,Universityof Duisburg-Essen,Essen,NRW,Germany,3Departmentof Diagnostic andInterventionalRadiologyandNeuroradiology,UniversityHospital Essen,Essen,NRW,Germany,4InstituteforMedicalInformatics,Biometry andEpidemiology(IMIBE),UniversityHospitalEssen,Essen,NRW,Germany*christoph.friedrich@fh-dortmund.deAbstractThenumberof imagestakenperpatientscanhasrapidlyincreaseddueto advancesin soft-ware,hardwareanddigitalimagingin themedicaldomain.Thereis theneedformedicalimageannotationsystemsthatareaccurateasmanualannotationis impractical, time-con-sumingandproneto errors.Thispaperpresentsmodelingapproachesperformedto auto-maticallyclassifyandannotateradiographsusingseveralclassificationschemes,whichcanbefurtherappliedforautomaticcontent-basedimageretrieval(CBIR)andcomputer-aideddiagnosis(CAD).Differentimagepreprocessingandenhancementtechniqueswereappliedto augmentgrayscaleradiographsbyvirtuallyaddingtwoextralayers.TheImageRetrievalin MedicalApplications(IRMA)Code,a mono-hierarchical multi-axialcode,servedasabasisforthiswork.Toextensivelyevaluatetheimageenhancementtechniques,fiveclassi-ficationschemesincludingthecompleteIRMAcodewereadopted.ThedeepconvolutionalneuralnetworksystemsInception-v3andInception-ResNet-v2,andRandomForestmodelswith1000treesweretrainedusingextractedBag-of-Keypoints visualrepresentations.TheclassificationmodelperformanceswereevaluatedusingtheImageCLEF2009MedicalAnnotationTasktestset.Theappliedvisualenhancementtechniquesprovedto achievebetterannotationaccuracyin allclassificationschemes.IntroductionWithrespecttothelastdecade,tentimesmoremedicalimagesaretaken,increasingthenum-berofimagesperbodyregionperpatientto200–1000[1].Thishugeincreasecanbetracedbacktotwomajorfacts:rapidadvancesintechnologyandsignificantimportanceofmedicalimages.Medicalimagescontainrelevantinformationthatis valuabletophysicians.It providesa reliablesourceofanatomicalandfunctionalinformationforaccuratediagnosis,effectivetreatmentplanningaswellasresearchwork[2,3].TheadvancesofsoftwareandhardwareinPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20181 / 18a1111111111a1111111111a1111111111a1111111111a1111111111OPENACCESSCitation:PelkaO, NensaF, Friedrich CM (2018)Annotationof enhancedradiographsfor medicalimageretrievalwith deepconvolutional neuralnetworks.PLoSONE 13(11):e0206229.https://doi.org/10.1371/journal.pone.0206229Editor:RuxandraStoean,Universityof Craiova,ROMANIAReceived:May 25, 2018Accepted:October5, 2018Published:November12, 2018Copyright:©2018Pelkaet al. This is an openaccessarticledistributedunderthe termsof theCreativeCommonsAttributionLicense,whichpermitsunrestricted use, distribution, andreproductionin any medium,providedthe originalauthorand sourceare credited.DataAvailability Statement:Figuresare availableafter licenceformare filled with ImageCELF2009MedicalAnnotationTask organisers.The sourcecodeis availableon GitHubvia the followingURL:https://github.com/obip/PlosONE_IRMA.Funding:The workof ObiomaPelkawas partiallyfundedby a PhD grantfromUniversity of AppliedSciencesand Arts Dortmund,Germany.Competinginterests:The authorshave declaredthat no competinginterestsexist.informationtechnologysectoranddigitalimaginginthemedicaldomainhavemadetheacquisitionandstorageofimagesinhospitalspossible[4].Thislargeimagecollectionaidsmedicalprofessionalsandimprovesdiagnosis.However,radiologistsarechallengedbytheamountofdata.Theyhavetomaintaina highinterpretationaccuracyofradiologicalimages,butalsomaximizeefficiencyintermsoftheincreasingnum-berofimagesperbodyregion.Computer-basedassistanceis neededforimageinterpretation,categorizationandannotation[5],asthesearebeneficialforcontent-basedimageretrieval(CBIR)systemsandcomputer-aideddiagnosis(CAD)[6].Deeplearningtechniques[7]haveimprovedpredictionaccuraciesinobjectdetection[8],speechrecognition[9]andindomainapplicationsuchasmedicalimaging[10,11].Hence,twoDeepConvolutionalNeuralNetwork(dCNN)systemswereadoptedforimageclassifica-tion.TocompareandevaluatetheperformanceofapplieddCNNsystems,a traditionalclassi-fierwasmodeledinaddition.Thispaperevaluatestheeffectofseveralimageenhancementtechniquesonthepredictionaccuracyrateonradiographs.Toanalyzethisvalue,severalclassificationschemeswereacquiredfromtheImageCLEF2009MedicalAnnotationTaskdataset.Allimagesusedatthetrainingandtestingstageswerepreprocessedwiththevariouspresentedimageenhancementtechniques.Finally,theobtainedimageannotationperformanceaccuraciesarecomparedanddiscussed.RelatedworkSeveralapproachestoInformationRetrieval(IR)inMedicalDomainasobjectivehavebeendesigned.KHRESMOIwasa largeEU-fundedprojectaimedatcreatinga multilingualandmultimodal-basedsearchsystemforbiomedicalinformationanddocumentation[12].TheGNUImage-FindingTool(GIFT),anoutcomeoftheViperProject,enablesuserstoperformquery-by-example(QBE)searchandimprovesresultqualitywithrelevancefeedback[13].In[14],ParallelDistributedImageSearchEngine(ParaDISE)wasproposed.Thissearchengineenablestheindexingandretrievingofimagesusingpresentvisualandtextfeatures.TheLuceneImageRetrieval(LIRE),a lightweightopensourcelibrary,providesimageretrievalusingvisualfeaturessuchascolorandtexture[15].TheIRMA-code,a mono-hierarchicalmulti-axialclassificationcodeformedicalimagewasproposedintheImageRetrievalinMedi-calApplications(IRMA)[16].TheIRMA-codedescribesthemodalityoftheimages,orienta-tionoftheimage,examinedbodyregionandthebiologicalsysteminvestigated.Positiveresultshavebeenachievedbyimagepreprocessingusinginputcolorenhancementtechniques.In[17],superiorvalueswereobtainedbyusingdualdeepconvolutionalneuralnetworksandcolorinputenhancement[18]todetectmalignancyindigitalmammographyimages.Ascomputer-aidedassistanceis neededinimageinterpretation[19]andimprovedpredictionaccuracieshavebeenobtainedusingdeepconvolutionalneuralnetworks[7],theobjectiveofthispaperis tocreateanautomaticimageannotationsystemusingdeeplearningandimageenhancementtechniques.Theseannotatedradiographsarefundamentalformedi-calimageretrievalsystems.Theaimofthispresentedapproachis toapplyseveralimageenhancementtechniquesonradiographs,toincreasetheoverallpredictionaccuracyofclassificationmodels.Thisis funda-mentalforimplementingimageretrievalsystems.MaterialDatasetThedatasetadoptedforevaluationwasdistributedattheImageCLEF2009MedicalAnnota-tiontask[20,21].Thetrainingsetconsistsof12,671grayscaleimagesandtheofficialAnnotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20182 / 18evaluationsethas1,732grayscaleimages.Eachradiographinthetrainingsetis annotatedwitha 13-characterstring.Fig1 showstworadiographswiththeannotations1121-127-732-500and1121-410-620-625,representing“XrayAnalogOverviewImage;CoronalAnteroposteriorSupine;LowerMiddleQuadrant;UropoieticSystem”and“XrayAnalogLowBeamEnergy;OtherObliqueOrientation;LeftBreast;ReproductiveFemaleSystemBreast”.Classificationschemes5 differentclassificationschemesareusedforevaluation,whichwerederivedbyusingthecompleteIRMAcode,aswellassplittingthecodetoits’fouraxes.IRMA.The13-digitcodeusedforannotationis knownastheIRMAcodeandwaspro-posedin[16].TheIRMAcodingsystemis hierarchicalandconsistsoffouraxes:thetechnicalFig1.Exampleoftwograyscaleradiographsannotatedwiththe13-digitclassificationcode.BothimageswererandomlychosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Republished from[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright[2009].https://doi.org/10.1371/journal.pone.0206229.g001Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20183 / 18code(T)forimagemodality,thedirectionalcode(D)forbodyorientations,theanatomicalcode(A)referringtobodyregionexamined,andthebiologicalcode(B)forthebiologicalsys-temexamined[16].Thecoderesultsina stringof13characters,ie.TTTT-DDD-AAA-BBB,whichcanbeseeninFig1.TheIRMAclassificationschemecontainsaltogether197individualclasses,whichrepresentthetotaldistinctcombinationsofallfouraxes.(T)technicalscheme.The(T)technicalclassificationschemeis thetechnicalaxisoftheIRMAcode.It consistsofa 4-characterstringanddenotesphysicalsource,modalityposition,techniquesandsub-techniques[16].TheT-schemehas6 classes.A randomexcerptofradio-graphsfromthetrainingsetannotatedwiththet-schemeis showninFig2.(D)directionalscheme.The(D)directionalclassificationschemeis a 3-characterstringanddenotestheorientationplaneoftheradiographs,suchascoronal,sagittalandtransversal[16].Thisschemeis madeupof34classes.A randomexcerptofradiographsfromthetrainingsetannotatedwiththed-schemeis showninFig3.(A)anatomicalscheme.The(A)classificationschemestandsforthecompletecodingofanatomicalregionswhicharepresentinthehumanbody.TheA-schemedefinesninemajorbodyregions,whereeachregionhas2 hierarchicalsub-regions[16].Intotal,theanatomicalschemehas97individualclassesandeachclassis representedbya 3-characterstring.A ran-domexcerptofradiographsfromthetrainingsetannotatedwiththea-schemeis showninFig4.(B)biologicalscheme.The(B)biologicalclassificationcodecategorizestheorganicsys-temscannedintotenmajorparts[16].TheB-schemecontains11classesandis representedbyFig2.ExamplesofradiographsannotatedwithtwoclassesfromtheT-scheme.(A)showsthreeimagesbelongingtoclass‘1124’representing‘Xray;PlainRadiology;Analog;LowBeamEnergy’and(B)displaysthreeimagesbelongingtoclass‘1123’representing ‘Xray;PlainRadiology;Analog;HighBeamEnergy’.AllradiographswererandomlychosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Republishedfrom[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright[2009].https://doi.org/10.1371/journal.pone.0206229.g002Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20184 / 18a 3-characterstring.A randomexcerptofradiographsfromthetrainingsetannotatedwiththeb-schemeis showninFig5.ImageenhancementInthissection,thethreeexperimentsadoptedforenhancingvisualrepresentationbeforetheclassificationandannotationoftheradiographsareexplained.ImagelayeringForimagerecognitiontasks,convolutionalneuralnetworkstrainedonlargedatasetsproducefavorableresults.ConsideringthenumberofimagesintheImageCLEF2009MedicalAnnota-tionTask,theadaptationofTransferLearningwithpre-trainedneural,suchasInception-v3[22]andInception-ResNet-v2[23],networkswaschosen.Thesepre-trainedDeepConvolu-tionalNeuralNetwork(dCNN)modelsweredesignedtoextractamongstotherfeatures,colorinformationfromtheimages[24,25].However,theradiographsdistributedforattheImage-CLEF2009MedicalAnnotationTaskaregrayscaleimagesandhavesinglecolorchannelwithvalues[0,255].TofullyutilizethecapabilitiesofdCNNs,twoextracolorlayersareaugmentedtoeachradiograph,completingtheRGBframeswiththeenhancedslices.Thefirstextralayerwasobtainedusingtheimageprocessingtechnique:ContrastLimitedAdaptiveHistorizationEquation(CLAHE)[18].CLAHEis a contrastenhancementmethod,modifiedfromtheAdaptiveHistogramEquation(AHE).It is designedtobebroadlyFig3.ExamplesofradiographsannotatedwithtwoclassesfromtheD-scheme.(A)showsthreeimagebelongingtoclass‘125’representing‘Coronal;Anteroposterior;Upright’and(B)displaysthreeimagesbelonging toclass‘228’representing‘Sagital;Lateral,left-right; Inclination’.Allradiographs wererandomlychosenfromtheImageCLEF 2009MedicalAnnotationTaskTrainingSet.Republished from[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright[2009].https://doi.org/10.1371/journal.pone.0206229.g003Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20185 / 18applicableandhavingdemonstratedeffectiveness,especiallyformedicalimages[26].Fig6displaystheoriginalradiographandthecorrespondingoutputimageafterCLAHEwasper-formed.TheCLAHEoutputimageswereobtainedusingthefollowingparameters:•  Numberoftiles:[8,8]•  Contrastenhancementlimit:0.01•  Numberofhistogrambins:256•  Rangeofoutputdata:Full•  Desiredhistogramshape:Uniform•  Distributionparameter:0.4ThesecondlayerwasgeneratedbyapplyingtheNonLocalMeans(NL-MEANS)prepro-cessingmethod.Thisis a digitalimagedenoisingmethod,basedona nonlocalaveragingofallpresentpixelsinanimage[27].TheeffectofapplyingNL-MEANStoa randomlychosenradiographfromtheImageCLEF2009MedicalAnnotationTaskTrainingSetis showninFig7.TheNL-MEANSoutputimageswereobtainedusingthefollowingparameters:•  Kernelratio:4•  Windowratio:4•  Filterstrength:0.05Fig4.ExamplesofradiographsannotatedwithtwoclassesfromtheA-scheme.(A)showsthreeimageseachbelonging toclass‘732’representing‘Abdomen; Lowerabdomen; Lowermiddlequadrant’and(B)displaysthreeimagesbelonging to‘213’representing‘Cranium;Facialcranium;Nosearea’.AllradiographswererandomlychosenfromtheImageCLEF 2009MedicalAnnotationTaskTrainingSet.Republished from[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright[2009].https://doi.org/10.1371/journal.pone.0206229.g004Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20186 / 18TheaugmentedRGB-Imageis obtainedbyaddingthetwolayerstotheoriginalgrayscaleradiograph,asshowninFig8.ImagepaddingTherearevariationsregardingtheheightandwidthoftheradiographsdistributedfortheIma-geCLEF2009MedicalAnnotationTask.Theupperandlowerextremitiesareusuallynarrowwithlesswidthsize,whileheadscansarewiderwithlessheightsize.Toobtainsizesimilarityoverallimages,a fixedsizewasdefined.Allradiographsinthedatasetwereresizedto[512x512]bypaddingtheinputimages,whichcanbeseeninFig9.Theimagesarepaddedwiththeirrepetition,otheralternativesarepaddingwitha constantvalueornoiseaswellasimagesquashing.Bothimagelayeringandpadding,asexplainedinsubsectionsImageLayeringandImagePadding,areappliedsuccessively;theoutputimageis showninFig10.ClassificationTensorFlowForthedCNNs,TensorFlow-Slim(TF-slim),a lightweightpackagefordefining,trainingandevaluatingmodelsinTensorFlow[28]withpre-trainedmodels,wasadopted.Tooptimizepre-dictionperformance,themodelswerefine-tunedwithalltrainableweightsandbesthyper-parameterconfigurationinthesecondtrainingphase.Fig5.ExamplesofradiographsannotatedwithtwoclassesfromtheB-scheme.(A)showsthreeimagsebelongingtoclass‘443’representing‘Gastrointestinalsystem;Smallintestine;Ileum’and(B)displaysthreeimagesbelonging toclass‘512’representing‘Uropoieticsystem;Kidney;Renalpelvis’.Allradiographswererandomly chosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Republished from[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright [2009].https://doi.org/10.1371/journal.pone.0206229.g005Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20187 / 18Inception-v3.Thepre-trainedmodelInception-v3[22]whichwastrainedfortheIma-geNet[24]LargeVisualRecognitionChallenge2012[29],wasusedtofine-tunetheclassifica-tionmodel.Tooptimizeclassificationaccuracy,a gridsearchwasusedtoobtainbesthyper-parametersconfigurations.FortheInception-v3classificationmodels,thefollowinghyper-parameterconfigurationwasapplied:•  Optimizer:RootMeanSquarePropagation(rmsprop)•  Numberofepochs:[1.Trainingphase= 2.5;2.Trainingphase= 25]•  Numberofsteps:[1.Trainingphase= 1,000;2.Trainingphase= 10,000]•  Batchsize:[1.Trainingphase= 2.5;2.Trainingphase= 25]•  Learningrate:0.01•  Learningratedecaytype:[1.Trainingphase= fixed;2.Trainingphase= exponential]•  Weightdecay:0.00004•  Modelname:Inception-v3Fig6.MedicalimagebeforeandafterContrastLimitedAdaptiveHistogramEquation(CLAHE)wasperformed.TheradiographwasrandomlychosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Republishedfrom[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright [2009].https://doi.org/10.1371/journal.pone.0206229.g006Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20188 / 18Forallotherparametersnotmentionedabove,thedefaultvaluesasproposedinTF-Slim[28]wereadopted.Inception-ResNet-v2.Thepre-trainedmodelInception-ResNet-v2[23]whichis avariationoftheInception-v3usingtheideaspresentedin[30,31],wasusedtofine-tunetheclassificationmodel.FortheInception-ResNet-v2classificationmodels,thefollowinghyper-parameterconfigurationwasapplied:•  Optimizer:RootMeanSquarePropagation(rmsprop)•  Numberofepochs:[1.Trainingphase= 2.5;2.Trainingphase= 25]•  Numberofsteps:[1.Trainingphase= 1,000;2.Trainingphase= 10,000]•  Batchsize:32•  Learningrate:0.01•  Learningratedecaytype:[1.Trainingphase= fixed;2.Trainingphase= exponential]•  Weightdecay:0.00004•  Modelname:Inception-ResNet-v2Forallotherparametersnotmentionedabove,thedefaultvaluesasproposedinTF-Slim[28]wereadopted.RandomForestRandomforest(RF)[32]modelswith1000deeptreesweretrainedtocompareaccuracyper-formancesamongstclassificationmodels.TheseRF-modelsweretrainedusingvisualimagerepresentationobtainedwiththeBag-of-Keypoints(BoK)[33]approach.Forwhole-imageFig7.MedicalimagebeforeandafterapplyingtheNonLocalMeans(NL-MEANS)preprocessing method.Theradiographwasrandomly chosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Republishedfrom[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright[2009].https://doi.org/10.1371/journal.pone.0206229.g007Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,20189 / 18classificationtasks,BoKapproachhasachievedhighclassificationaccuracyresults[34,35].BoKis basedonvectorquantizationofaffineinvariantdescriptorsofimagepatches[33].Thesimplicityandinvariancetoaffinetransformationareadvantagesthatcomewiththisapproach.AllfunctionsappliedtorendervisualmodelsarefromtheVLFEATlibrary[36].DenseSIFT(dSIFT)[37]appliedatseveralresolutionswereuniformlyextractedwithanintervalof4pixelsusingtheVL-PHOWfunction.Computationaltimewasspedupbycomputingk-meansclusteringwithApproximatedNearestNeighbor(ANN)[38]onrandomlychosendescriptorsFig8.Enhancedgrayscaleradiograph,byaugmenting2 extracolorlayerstoobtaina RGB-channeledmedicalimage.TheradiographswererandomlychosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Republishedfrom[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright [2009].https://doi.org/10.1371/journal.pone.0206229.g008Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201810/ 18usingtheVL-KMEANSfunction.Thispartitionstheobservationsintokclusterssothatthewithin-clustersumofsquareis minimized.A maximumnumberof20iterationswasdefinedtoallowthek-meansalgorithmtoconvergeandclustercenterswereinitializedusingrandomdatapoints[39].A codebookFig9.Resizedradiographsbypadding inputimagestothedefinedwidthandheightsize[512x 512].(A)showshorizontaland(B)verticalpadding.TheradiographswererandomlychosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Modifiedfrom[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright[2009].https://doi.org/10.1371/journal.pone.0206229.g009Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201811/ 18containing1,000keypointswasgeneratedask= 1,000.UsingtheVL-KDTREEBUILDfunc-tion,thecodebookwasfurtheroptimizedbyadaptinga kd-treewithmetricdistanceL2forquicknearestneighborlookup.ParametersusedtotuneBoKandRFare:•  Codebooksize:1,000•  Numberofdescriptorsextracted:1,000•  Visualrepresentationsize:4,000(2x2grid)•  Featuresizereduction:4000to100(PrincipalComponentAnalysis)•  Numberoftrees(RF):1,000•  Ensemblemethod(RF):BagResultsImageclasspredictionwascomputedusingfiveclassificationschemes:thecompleteIRMAcodeandits4 axesseparately.Theperformanceofmodeledclassifiersondifferentclassifica-tionschemesarelistedinTables1–3,forRandomForest,Inception-v3andInception-ResNet-v2,respectively.Evaluationwasperformedontheofficialtestsetandallmodelsweretrainedwiththecom-pletetrainingsetdistributedattheImageCLEF2009MedicalAnnotationTask.Fig10.Outputimageaftersuccessivelyapplyingtheimagepadding andimagelayeringenhancementtechniques.TheradiographswererandomlychosenfromtheImageCLEF2009MedicalAnnotationTaskTrainingSet.Modifiedfrom[21]undera CCBYlicense,withpermissionfrom[RWTHAachen],originalcopyright [2009].https://doi.org/10.1371/journal.pone.0206229.g010Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201812/ 18Thebestpredictionperformancesperclassifiermodelandimageinputobtainedonthedif-ferentclassificationschemesaredisplayedinTables4–8foreasierunderstanding.EvaluationwascalculatedforusingtheImageCLEF2009MedicalAnnotationTasktestset.DiscussionIt canbeseenfromallresulttables,betterpredictionaccuraciesareobtainedwiththeenhancedradiographs.Thisis observedforallthreeclassificationmodelsandallfiveschemesTable3.PredictionperformanceoftheInception-ResNet-v2imageclassificationmodelonthevariousimageinputtypes.Thehighlightedaccuracies arethebestperclassificationscheme.EvaluationwascalculatedontheImageCLEF2009MedicalAnnotationTaskTestSet.InputImageT-CodeD-CodeA-CodeB-CodeIRMAImagePadding99.22%78.50%57.8996.78%51.22%ImagePadding/Layered99.28%75.72%59.83%89.22%49.83%ImageLayered98.67%77.61%53.44%92.83%49.31%CLAHEImage98.06%76.11%51.22%95.56%43.33%NLMEANSImage97.00%70.89%49.44%94.61%42.00%OriginalImage97.33%73.88%49.94%94.67%42.67%https://doi.org/10.1371/journal.pone.0206229.t003Table4.Bestprediction performancesfortheappliedclassificationmodels.Theclassificationschemeis (T)techni-calaxisandcontains6 classes.InputImageClassifierPerformanceImageLayeredRandomForest98.09%ImagePaddingInception-v399.21%ImageLayered/PaddingInception-ResNet-v299.28%https://doi.org/10.1371/journal.pone.0206229.t004Table1.PredictionperformanceoftheRandomForestimageclassificationmodelonthevariousimageinputtypes.Thehighlightedaccuraciesarethebestperclassi-ficationscheme.EvaluationwascalculatedontheImageCLEF2009MedicalAnnotationTaskTestSet.InputImageT-CodeD-CodeA-CodeB-CodeIRMAImagePadding97.98%63.57%53.35%92.21%48.67%ImagePadding/Layered97.52%62.47%51.15%92.32%47.98%ImageLayered98.09%63.05%54.39%91.40%48.96%CLAHEImage97.69%60.68%50.46%91.97%45.84%NLMEANSImage97.58%61.89%49.42%91.22%45.09%OriginalImage97.00%61.64%51.15%90.76%47.11%https://doi.org/10.1371/journal.pone.0206229.t001Table2.PredictionperformanceoftheInception-v3imageclassificationmodelonthevariousimageinputtypes.Thehighlightedaccuraciesarethebestperclassifica-tionscheme.EvaluationwascalculatedontheImageCLEF2009MedicalAnnotationTaskTestSet.InputImageT-CodeD-CodeA-CodeB-CodeIRMAImagePadding99.21%76.61%60.33%96.39%46.39%ImagePadding/Layered99.06%79.11%56.67%95.78%47.00%ImageLayered98.83%74.33%50.22%93.78%39.77%CLAHEImage98.61%71.72%45.77%93.61%39.44%NLMEANSImage96.78%69.33%43.06%95.22%40.44%OriginalImage97.89%70.00%44.33%91.50%39.33%https://doi.org/10.1371/journal.pone.0206229.t002Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201813/ 18adopted.However,thereis notoneenhancementtechniquethatoutperformstherest,it varieswiththeclassificationschemeused,whichcanbeexplainedbythenofreelunchtheorem[40].Certainenhancementtechniquesperformbetteratsomeclassificationschemes.ImageLay-eredachievesbestresultswhentrainedwiththeBag-of-KeywordsandRandomForest.ImagePaddingperformsbestwithmodelstrainedwiththedeeplearningsystemInception-v3.FormodelstrainedwithInception-ResNet-v2,ImageLayered/Paddingleadstobetterresults.Bestpredictionperformancewasobtainedwiththefollowingmodelandenhancementtechniquecombination:•  (T)technical:ImagePaddingandLayeringwithInception-ResNet-v2•  (D)directional:ImagePaddingandLayeringwithInception-v3•  (A)anatomical:ImagePaddingwithInception-v3•  (B)biological:ImagePaddingwithInception-ResNet-v2•  IRMA:ImagePaddingwithInception-ResNet-v2Table8.Bestprediction performancesfortheappliedclassificationmodels.Theclassificationschemeis thecom-pleteIRMAcode,whichhas193classes.InputImageClassifierPerformanceImageLayeredRandomForest48.96%ImagePaddingInception-v347.00%ImagePaddingInception-ResNet-v251.22%https://doi.org/10.1371/journal.pone.0206229.t008Table5.Bestprediction performancesfortheappliedclassificationmodels.Theclassificationschemeis (D)direc-tionalaxisandcontains34classes.InputImageClassifierPerformanceImagePaddingRandomForest63.57%ImageLayered/PaddingInception-v379.11%ImagePaddingInception-ResNet-v278.50%https://doi.org/10.1371/journal.pone.0206229.t005Table6.Bestprediction performancesfortheappliedclassificationmodels.Theclassificationschemeis (A)ana-tomicalaxisandcontains97classes.InputImageClassifierPerformanceImageLayeredRandomForest54.39%ImagePaddingInception-v360.33%ImageLayered/PaddingInception-ResNet-v259.83%https://doi.org/10.1371/journal.pone.0206229.t006Table7.Bestpredictionperformancesfortheappliedclassificationmodels.Theclassificationschemeis (B)biologi-calsystemaxisandcontains11classes.InputImageClassifierPerformanceImageLayered/PaddingRandomForest92.32%ImagePaddingInception-v396.39%ImagePaddingInception-ResNet-v296.78%https://doi.org/10.1371/journal.pone.0206229.t007Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201814/ 18Asthenumberofclassesincrease,thepredictionaccuracyratedecreases.TheanatomicalandIRMAschemesareclassimbalanced,havinglessornoimagerepresentingsomeclasses.Hence,theuncertaintyofthemodelsis highattheseimages.ThepredictionresultsoftheIRMAschemeis lowest,asit containsthehighestnumberofclassesofsparserepresentations.However,a hierarchicalclassificationcanbeusedtotacklethistask,astheresultsintheindi-vidualaxesperformwell.Followingtheshownresults,a morerobustandcertainmodelcanbeobtainedwitha bal-ancedclassdistributionoftheimagesinthetrainingset.Anensembleofmodelstrainedwithseveralimageenhancementtechniquesshouldbeappliedwithmajorityvote,toachievetheoptimaltrainingmodelandenhancementtechniquecombination.ConclusionInthispaper,grayscaleradiographenhancementmethodsaimingtoachievebetterclassifica-tionandannotationperformanceis presented.Twoextracolorlayersareaugmentedtosimu-lateRGB-channeledimages,asDeepConvolutionalNeuralNetworks(dCNN)usecolorinformationfortraining.Duetovariationsinwidthsizeandheightsize,theradiographsarepaddedwithcroppedpatchestofillupthedefinedsize[512x 512].ThedCNNsystemsInception-v3andInception-ResNet-v2wereappliedasimageclassifi-cationmodels.ThetraditionalmachinelearningalgorithmRandomForest(RF),trainedwithBag-of-Keypointsvisualrepresentation,wasadoptedforperformancecomparison.Fiveclassificationschemes,eachhavingdifferentnumberofclassesandcategorizationfocus,wereappliedtoevaluatetheimageenhancementtechniques.Thisworksshowsthatenhancingtheradiographsbeforetrainingandclassification,provestoobtainpositiveresults.Thisis observedforthemodelstrainedwiththedeeplearningsys-temsInception-v3andInception-ResNet-v2,aswellasthetraditionalcombinationofBag-of-KeypointsandRandomForest.Forallfiveclassificationschemes,betterpredictionaccuracieswereachievedwhentheenhancedradiographswereused.Prospectiveevaluationofannotatingradiographscanbebasedonmulti-modalimagerepresentationandhierarchicalclassannotation,aspositiveresultshavebeenpresentedinrecentapproaches.AcknowledgmentsTheworkofObiomaPelkawaspartiallyfundedbya PhDgrantfromtheUniversityofAppliedSciencesandArtsDortmund(FHDO),Germany.TheauthorswouldliketothankThomasM.DesernofromtheDepartmentofMedicalInformatics,RWTHAachenGermany,forprovidinguswithImageCLEF2009MedicalAnno-tationtrainingandtestsets.Uponusage,thesourceofdatashouldbereferencedandcanbeobtainedfrom[21].AuthorContributionsDatacuration:ObiomaPelka.Methodology:ChristophM.Friedrich.Software:ObiomaPelka.Supervision:ChristophM.Friedrich.Validation:ObiomaPelka,FelixNensa.Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201815/ 18Visualization:ObiomaPelka.Writing– originaldraft:ObiomaPelka.Writing– review&editing:FelixNensa,ChristophM.Friedrich.References1.NensaF, ForstingM,WetterA.ZukunftderRadiologie.DerUrologe. 2016;55(3):350–355.https://doi.org/10.1007/s00120-016-0045-12.SchaerR,Mu ̈ llerH.A modernwebinterfaceformedicalimageretrieval.SwissMedicalInformatics.2014;30.3.RahmanMM,BhattacharyaP,DesaiBC.A FrameworkforMedicalImageRetrievalUsingMachineLearningandStatisticalSimilarityMatchingTechniquesWithRelevance Feedback.IEEETransactionsonInformation Technologyin Biomedicine.2007;11(1):58–69. https://doi.org/10.1109/TITB.2006.884364PMID:172494044.TagareHD,JaffeCC,DuncanJS.Synthesisof Research:MedicalImageDatabases:A Content-basedRetrievalApproach.Journalof theAmericanMedicalInformatics AssociationJAMIA.1997;4(3):184–198.5.Akgu ̈ l CB,RubinDL,NapelS,BeaulieuCF,GreenspanH,AcarB.Content-BasedImageRetrievalinRadiology: CurrentStatusandFutureDirections.J DigitalImaging.2011;24(2):208–222.https://doi.org/10.1007/s10278-010-9290-96.RothHR,LuL, LiuJ, YaoJ, SeffA,CherryKM,et al.ImprovingComputer-AidedDetectionUsingCon-volutional NeuralNetworksandRandomViewAggregation. IEEETransMedImaging.2016;35(5):1170–1181.https://doi.org/10.1109/TMI.2015.2482920 PMID:264414127.LeCunY,BengioY,HintonGE.DeepLearning.Nature.2015;521(7553):436–444. https://doi.org/10.1038/nature14539PMID:260174428.DenselyConnectedConvolutional Networks.IEEE;2017.Available from:https://doi.org/10.1109%2Fcvpr.2017.243.9.HintonG,DengL, YuD,DahlG,MohamedAa,JaitlyN,et al.DeepNeuralNetworksforAcousticModeling in SpeechRecognition: TheSharedViewsof FourResearchGroups.IEEESignalProcessingMagazine.2012;29(6):82–97. https://doi.org/10.1109/MSP.2012.220559710.AbraoMS,Gonc ̧alvesMOdC,DiasJAJr,PodgaecS,Chamie LP,BlasbalgR.Comparisonbetweenclinicalexamination, transvaginal sonographyandmagneticresonanceimagingforthediagnosis ofdeependometriosis.HumanReproduction.2007;22(12):3092–3097. https://doi.org/10.1093/humrep/dem187PMID:1794737811.XuY,MoT, FengQ,ZhongP,LaiM,ChangEI.Deeplearningof featurerepresentationwithmultipleinstancelearningformedicalimageanalysis.In:IEEEInternationalConferenceonAcoustics, SpeechandSignalProcessing, ICASSP2014,Florence,Italy,May4-9,2014;2014.p. 1626–1630.Availablefrom:https://doi.org/10.1109/ICASSP.2014.6853873.12.KellyL, DungsS,KriewelS,HanburyA,GoeuriotL, JonesGJF,et al.Khresmoi Professional:Multilin-gual,MultimodalProfessionalMedicalSearch.In:Advancesin Information Retrieval—36thEuropeanConferenceonIRResearch,ECIR2014,Amsterdam,TheNetherlands, April13-16,2014.Proceed-ings;2014.p. 754–758.Available from:https://doi.org/10.1007/978-3-319-06028-6_89.13.Mu ̈ llerH,Mu ̈ llerW,SquireD,Marchand-MailletS,PunT. Performanceevaluation in content-basedimageretrieval:overviewandproposals. PatternRecognitionLetters.2001;22(5):593–601.https://doi.org/10.1016/S0167-8655(00)00118-514.SchaerR,MarkonisD,Mu ̈ llerH.Architectureandapplicationsof theParallelDistributedImageSearchEngine(ParaDISE). In:44.JahrestagungderGesellschaft fu ̈ r Informatik,Informatik2014,BigData—Komplexita ̈t meistern,22.-26.September 2014in Stuttgart,Deutschland;2014.p. 661–666.Availablefrom:http://subs.emis.de/LNI/Proceedings/Proceedings232/article43.html.15.LuxM,ChatzichristofisSA.Lire:luceneimageretrieval:anextensible javaCBIRlibrary.In:Proceed-ingsof the16thInternationalConference onMultimedia 2008,Vancouver,BritishColumbia,Canada,October26-31,2008;2008.p. 1085–1088.Availablefrom:http://doi.acm.org/10.1145/1459359.1459577.16.LehmannTM,Gu ̈ ld MO,ThiesC,PlodowskiB,KeysersD,OttB,et al.IRMA—Content-BasedImageRetrievalin MedicalApplications.In:MEDINFO2004—Proceedingsof the11thWorldCongressonMedicalInformatics,SanFrancisco, California,USA,September 7-11,2004;2004.p. 842–846. Avail-ablefrom:https://doi.org/10.3233/978-1-60750-949-3-842.Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201816/ 1817.TeareP,FishmanM,BenzaquenO,Toledano E,ElnekaveE.MalignancyDetectiononMammogra-phyUsingDualDeepConvolutional NeuralNetworks andGeneticallyDiscovered FalseColorInputEnhancement.J DigitalImaging.2017;30(4):499–505. https://doi.org/10.1007/s10278-017-9993-218.Zuiderveld K.GraphicsGemsIV.1994;p. 474–485.19.LitjensGJS,KooiT, BejnordiBE,SetioAAA,CiompiF, Ghafoorian M,et al.A surveyondeeplearningin medicalimageanalysis.MedicalImageAnalysis.2017;42:60–88. https://doi.org/10.1016/j.media.2017.07.005PMID:2877802620.Tommasi T, CaputoB,WelterP,Gu ̈ ld MO,DesernoTM.Overview of theCLEF2009MedicalImageAnnotationTrack.In:MultilingualInformation AccessEvaluationII. MultimediaExperiments—10thWorkshopof theCross-LanguageEvaluationForum,CLEF2009,Corfu,Greece,September 30—October2, 2009,RevisedSelectedPapers;2009.p. 85–93.Availablefrom:https://doi.org/10.1007/978-3-642-15751-6_9.21.DesernoTM,OttB.15,363IRMAimagesof 193categoriesforImageCLEFmed2009.Availablefrom:http://dx.doi.org/10.18154/RWTH-2016-06143.22.SzegedyC,VanhouckeV,IoffeS,ShlensJ, WojnaZ. RethinkingtheInceptionArchitecture forCom-puterVision.In:2016IEEEConferenceonComputerVisionandPattern Recognition, CVPR2016,LasVegas,NV,USA,June27-30,2016;2016.p. 2818–2826.Availablefrom:https://doi.org/10.1109/CVPR.2016.308.23.SzegedyC,IoffeS,VanhouckeV,AlemiAA.Inception-v4,Inception-ResNetandtheImpactof Resid-ualConnectionsonLearning.In:Proceedingsof theThirty-FirstAAAIConferenceonArtificialIntelli-gence,February4-9,2017,SanFrancisco, California,USA.;2017.p. 4278–4284.Availablefrom:http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14806.24.KrizhevskyA,SutskeverI, HintonGE.ImageNetClassificationwithDeepConvolutionalNeuralNet-works.In:Proceedingsof the25thInternationalConferenceonNeuralInformation Processing Systems—Volume1. NIPS’12.USA:CurranAssociates Inc.;2012.p. 1097–1105.Availablefrom:http://dl.acm.org/citation.cfm?id=2999134.2999257.25.GoodfellowI, BengioY,CourvilleA.DeepLearning.Adaptivecomputationandmachinelearningseries.TheMITPress;2016.26.PizerSM,AmburnEP,AustinJD,CromartieR,Geselowitz A,GreerT, et al.AdaptiveHistogramEqual-izationandItsVariations.ComputVisionGraphImageProcess.1987;39(3):355–368.https://doi.org/10.1016/S0734-189X(87)80186-X27.BuadesA,CollB,MorelJM.A Non-LocalAlgorithmforImageDenoising.In:Proceedingsof the2005IEEEComputerSocietyConferenceonComputerVisionandPatternRecognition(CVPR’05)—Volume2—Volume 02.CVPR’05.Washington, DC,USA:IEEEComputerSociety;2005.p. 60–65.Availablefrom:http://dx.doi.org/10.1109/CVPR.2005.38.28.AbadiM,AgarwalA,BarhamP,BrevdoE,ChenZ, CitroC,et al.TensorFlow:Large-Scale MachineLearningonHeterogeneousSystems; 2015.Available from:https://www.tensorflow.org/.29.RussakovskyO,DengJ, SuH,KrauseJ, SatheeshS,MaS,et al.ImageNet LargeScaleVisualRecog-nitionChallenge. InternationalJournalof ComputerVision(IJCV).2015;115(3):211–252.https://doi.org/10.1007/s11263-015-0816-y30.HeK,ZhangX,RenS,SunJ. DeepResidualLearningforImageRecognition. In:ConferenceonCom-puterVisionandPatternRecognitionCVPR.IEEEComputerSociety;2016.p. 770–778.31.HeK,ZhangX,RenS,SunJ. IdentityMappings in DeepResidualNetworks.In:EuropeanConferenceonComputerVisionECCV. vol.9908of LectureNotesin ComputerScience.Springer;2016.p. 630–645.32.BreimanL. RandomForests.MachineLearning.2001;45(1):5–32. https://doi.org/10.1023/A:101093340432433.CsurkaG,DanceCR,FanL, Willamowski J, BrayC.Visualcategorizationwithbagsof keypoints.In:InWorkshoponStatisticalLearningin ComputerVision,ECCV;2004.p. 1–22.34.Lazebnik S,SchmidC,PonceJ. BeyondBagsof Features: SpatialPyramidMatchingforRecognizingNaturalSceneCategories. In:Proceedingsof the2006IEEEComputerSocietyConferenceonCom-puterVisionandPatternRecognition—Volume2. CVPR’06;2006.p. 2169–2178.35.ZhangH,BergAC,MaireM,MalikJ. SVM-KNN:DiscriminativeNearestNeighborClassificationforVisualCategoryRecognition.In:Proceedingsof the2006IEEEComputerSocietyConferenceonCom-puterVisionandPatternRecognition—Volume2. CVPR’06;2006.p. 2126–2136.36.VedaldiA,FulkersonB.VLFEAT:anopenandportablelibraryof computervisionalgorithms. In:Pro-ceedings of the18thInternationalConferenceonMultimedia2010,Firenze,Italy,October25-29,2010;2010.p. 1469–1472.Availablefrom:http://doi.acm.org/10.1145/1873951.1874249.Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201817/ 1837.Li FF,PeronaP.A BayesianHierarchicalModelforLearningNaturalSceneCategories. In:Proceed-ingsof the2005IEEEComputerSocietyConferenceonComputerVisionandPattern Recognition(CVPR’05)—Volume2—Volume 02.CVPR’05;2005.p. 524–531.38.IndykP,MotwaniR.ApproximateNearestNeighbors: TowardsRemoving theCurseof Dimensionality.In:Proceedingsof the30thAnnualACMSymposiumonTheoryof Computing.STOC’98. NewYork,NY,USA:ACM;1998.p. 604–613.39.HartiganJA,WongMA.A k-meansclusteringalgorithm.JSTOR:AppliedStatistics. 1979;28(1):100–108.40.WolpertDH,MacreadyWG.NoFreeLunchTheoremsforOptimization.TransactionsonEvolutionaryComputing.1997;1(1):67–82. https://doi.org/10.1109/4235.585893Annotationof enhanced radiographsformedicalimageretrieval withdeepconvolutionalneuralnetworksPLOSONE| https://doi.org/10.1371/journal.pone.0206229November12,201818/ 18CopyrightofPLoSONEisthepropertyofPublicLibraryofScienceanditscontentmaynotbecopiedoremailedtomultiplesitesorpostedtoalistservwithoutthecopyrightholder'sexpresswrittenpermission.However,usersmayprint,download,oremailarticlesforindividualuse.