Research ArticleDeep Neural Network-Based Method for Detecting Central RetinalVein Occlusion Using Ultrawide-Field Fundus OphthalmoscopyDaisuke Nagasato,1Hitoshi Tabuchi,1Hideharu Ohsugi,1Hiroki Masumoto,1Hiroki Enno,2Naofumi Ishitobi,1Tomoaki Sonobe,1Masahiro Kameoka,1Masanori Niki,3Ken Hayashi,4and Yoshinori Mitamura31Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan2Rist Inc., Tokyo, Japan3Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University Graduate School, Tokushima, Japan4Hayashi Eye Hospital, Fukuoka, JapanCorrespondence should be addressed to Daisuke Nagasato; d.nagasato@tsukazaki-eye.netReceived 5 September 2018; Accepted 17 October 2018; Published 1 November 2018Academic Editor: EladMoisseievCopyright© 2018 Daisuke Nagasato et al. +is is an open access article distributed under the Creative Commons AttributionLicense, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work isproperly cited.+e aim of this study is to assess the performance of two machine-learning technologies, namely, deep learning (DL) andsupport vector machine (SVM) algorithms, for detecting central retinal vein occlusion (CRVO) in ultrawide-field fundusimages. Images from 125 CRVO patients (n�125   images) and 202 non-CRVO normal subjects (n�238   images) wereincluded in this study. Training to construct the DL model using deep convolutional neural network algorithms was providedusing ultrawide-field fundus images. +e SVM uses scikit-learn library with a radial basis function kernel. +e diagnosticabilities of DL and the SVM were compared by assessing their sensitivity, specificity, and area under the curve (AUC) of thereceiver operating characteristic curve for CRVO. For diagnosing CRVO, the DL model had a sensitivity of 98.4% (95%confidence interval (CI), 94.3–99.8%) and a specificity of 97.9% (95% CI, 94.6–99.1%) with an AUC of 0.989 (95% CI,0.980–0.999). In contrast, the SVM model had a sensitivity of 84.0% (95% CI, 76.3–89.3%) and a specificity of 87.5% (95% CI,82.7–91.1%) with an AUC of 0.895 (95% CI, 0.859–0.931). +us, the DL model outperformed the SVM model in all indicesassessed (P<0.001for all). Our data suggest that a DL model derived using ultrawide-field fundus images could distinguishbetween normal and CRVO images with a high level of accuracy and that automatic CRVO detection in ultrawide-field fundusophthalmoscopy is possible. +is proposed DL-based model can also be used in ultrawide-field fundus ophthalmoscopy toaccurately diagnose CRVO and improve medical care in remote locations where it is difficult for patients to attend anophthalmic medical center.1. IntroductionCentral retinal vein occlusion (CRVO) is a vascular diseaseof the eye and a known cause of significant visual morbidity,including sudden blindness [1]. Pathogenesis of CRVO isbelieved to follow the principles of Virchow’s triad ofthrombogenesis, namely, vessel damage, stasis, and hyper-coagulability [2]. In CRVO, the fundus may show retinalhemorrhages, dilated tortuous retinal veins, cotton-woolspots, optic edema, and macular edema (ME); ME is themost important cause of visual impairment in CRVO [3].Intravitreous injections of antivascular endothelial growthfactor (VEGF) agents have been shown to significantlyimprove visual acuity in eyes with CRVO-associated ME [4].However, any delay in treatment with anti-VEGF agentsresults in poor functional improvement, and it is difficult tosubsequently achieve satisfactory improvement in vision[5–7].+us, it is important to treat CRVO patients in anophthalmic specialty center immediately after the onset topreserve visual function. However, establishing a largenumber of such centers is impractical because of risingHindawiJournal of OphthalmologyVolume 2018, Article ID 1875431, 6 pageshttps://doi.org/10.1155/2018/1875431public healthcare costs, a problem that is burdening severalnations worldwide [8].Recent remarkable advances in medical equipmentinclude the ultrawide-field scanning laser ophthalmo-scope, the Optos 200T×(Optos PLC, Dunfermline, UnitedKingdom). +e Optos can easily and noninvasively pro-vide wide-field fundus images (Figure 1) without mydriaticagent use, and it has been used for diagnosing or moni-toring multiple conditions and for treatment evaluation inperipheral retinal and vascular pathology [9]. Importantly,if pupillary block and elevated intraocular pressure as-sociated with dilation can be avoided, a trained non-medical personnel can safely capture images to use them intelemedicine applications, especially in areas withoutophthalmologists.Image  processing  approaches  using  two  machine-learning algorithms, namely, deep learning (DL) and sup-port vector machines (SVMs), have retained investigatorattention  for  years  because  of  their  extremely  high-performance levels; in fact, increasing number of studieshave assessed their applications in medical imaging [10–14].Nonetheless, in ophthalmology, the use of image processingtechnology that uses DL algorithms and SVM models toanalyze medical images has been previously reported[13, 15, 16]. However, to the best of our knowledge, no studyhas evaluated the possibility of automated CRVO diagnosisusing Optos images and machine-learning technology.+erefore, in this study, we assessed the ability of a DL modelto detect CRVO using Optos images and compared theresults between DL- and SVM-based algorithms.2. Materials and Methods2.1.  Image  Dataset.Optos images of patients with acuteCRVO and those without fundus diseases were extractedfrom the clinical database of the ophthalmology de-partments of the Tsukazaki Hospital, Tokushima UniversityHospital, and Hayashi Eye Hospital. +ese images werereviewed by a retinal specialist and stored in an analyticaldatabase. Of the 363 fundus images selected, 125 were fromCRVO patients and 238 were from non-CRVO healthysubjects.We usedK-fold cross validation in this study, and it hasbeen described in detail elsewhere [17, 18]. Briefly, imagedata were divided intoKgroups, and (K−1) groups wereused as training data, whereas one data group was used forvalidation. +is process was repeatedKtimes until each oftheKgroups became a validation dataset. +e number ofgroups (K) was calculated using Sturges’ formula (K�1 +log2N). Sturges’ formula is used to decide the number ofclasses in the histogram [19, 20]. +us, in this study, wecategorized the data into nine groups.Images in the training dataset were augmented byadjusting for brightness, gamma correction, histogramequalization, noise addition, and inversion so that theamount of training data increased by 18-fold. +e deepconvolutional neural network (DNN) model, as detailedbelow, was created and was trained using preprocessedimage data.+is study was conducted in compliance with theprinciples of the Declaration of Helsinki and was approvedby the ethics committees of Tsukazaki Hospital, TokushimaUniversity Hospital, and Hayashi Eye Hospital.2.2. Deep Learning Model and Training.A DNN model calledthe Visual Geometry Group-16 (VGG-16) [21] was used inthe present study, and its schematic is shown in Figure 2.+is type of DNN is configured to automatically learn localfeatures of images and generate a classification model[22–24]. +e aspect ratio of the original Optos images was3,900×3,072 pixels; however, for analysis, we changed theaspect ratio of all input images and resized them to 256×192pixels. As the RGB input of images had a range of 0–255, itwas first normalized to a range of 0–1 by dividing it by 255.+e VGG-16 model comprises five blocks and three fullyconnected layers. Each block includes convolutional layersfollowed by a max-pooling layer with decreasing positionsensitivity but greater generic recognition [25]. Flattening ofthe output from block 5 results in only two fully connectedlayers. +e first layer removes spatial information from theextracted feature vectors, and the second layer is a classifi-cation layer that uses feature vectors from target imagesacquired in previous layers in combination with the softmaxfunction for binary classification. To improve generalizationperformance, dropout processing was performed such thatmasking was achieved with a probability of 25% in the firstfully connected layer.Fine tuning was used to increase the learning speed andachieve higher performance with lower quantitates of data[26, 27]. We used the following parameters from ImageNet:blocks 1 to 4 were fixed, whereas block 5 and the fullyconnected layers were trained.+e weights of block 5 and the fully connected layers wereupdated using the optimization momentum stochastic gra-dient descent algorithm (learning coefficient�0.0005, inertialterm�0.9) [28, 29]. Of the 40 DL models obtained in 40learning cycles, the one with the highest rate of correct an-swers for the test data was selected as the DL model tobe evaluated in this study. For this purpose, Keras (https://keras.io/ja/) was run on TensorFlow (https://www.tensorflow.org/) written in Python and was used to build and evaluate themodel. We trained the model using the CPU of Core (TM)i7-8700K by Intel and the GPU of GeForce GTX 1080 Ti byNVIDIA.2.3.  Support  Vector  Machine  Model.We used the soft-margin SVM implemented in the scikit-learn library usingthe radial basis function kernel [30]. We reduced all imagesto 60 dimensions as this was the number of dimensions thatwas found to provide the highest correct answer rate for thetest data; for this, we tested 10–70 dimensions in steps of 10.+e optimal values for cost parameter “C” of the SVM al-gorithm and parameter “c” of the radial basis function weredetermined by grid search using quadrant cross validation,and the combination with the highest average correct answerrate was selected. +e parameter values tested forCwere1, 10, 100, and 1000 and those forcwere 0.0001, 0.001, 0.01,2Journal of Ophthalmology0.1, and 1. +e final learning model was generated using theoptimized parameter values ofC�10 andc�0.0001.2.4.   Outcomes.Receiver operating characteristic (ROC)curves for CRVO were created on the basis of the ability ofthe DL and SVM models to distinguish between CRVO andnon-CRVO images, and the models were compared usingarea under the curve (AUC), sensitivity, and specificityvalues.2.5.  Heat  Map.A heat map of the DNN focus site wascreated and classified using gradient-weighted class acti-vation mapping [21]. Next, composite images were createdby overlaying heat maps of the DNN focus site on thecorresponding CRVO and non-CRVO images. +e thirdconvolution layer in block 3 was defined as the target layer,and the rectified linear unit was used as the backpropmodifier. +is process was performed using Python Keras-vis (https://raghakot.github.io/keras-vis/).2.6. Statistical Analysis.Patient demographic data such asage were compared using Student’st-test, whereas Fisher’sexact test was used for comparing the gender ratio and theratio of the right to left eye images.+e 95% confidence interval (CI) of AUC was obtainedas follows. Images judged to exceed a threshold were de-fined as positive for CRVO, and the ROC curve was created.We created nine such models and nine ROC curves. Fordetermining AUC, the 95% CI was obtained by assumingnormal distribution and using the average and standarddeviation of the nine ROC curves. For estimating sensitivityand specificity, optimal cutoff values, which are the pointsclosest to the point at which both sensitivity and specificityare 100% in each ROC curve, were used [26]. +e sensitivityand specificity at the optimal cutoff value were calculatedfi2×2fi2convL23Ifi2×2fi2convL23I/ax2poolingPlock2)Plock2VPlock2fiPlock2jPlock2I/ax2poolingqlattenqc2Vj3qc2Vfi2×2fi2convL2Vj3fi2×2fi2convL2Vj3fi2×2fi2convL2Vj3/ax2poolingfi2×2fi2convL2j)Vfi2×2fi2convL2j)Vfi2×2fi2convL2j)V/ax2poolingfi2×2fi2convL2j)Vfi2×2fi2convL2j)Vfi2×2fi2convL2j)Vfi2×2fi2convL2)VUfi2×2fi2convL2)VU/ax2poolingFigure2: Overall architecture of Visual Geometry Group-16 model. Visual Geometry Group-16 (VGG-16) comprises five blocks and threefully connected layers. Each block includes convolutional layers followed by a max-pooling layer. Flattening of the output matrix after block5 resulted in two fully connected layers for binary classification. +e deep convolutional neural network used ImageNet parameters; theweights of blocks 1–4 were fixed, whereas the weights of block 5 and the fully connected layers were adjusted.Figure1: Representative fundus images obtained using ultrawide-field scanning laser ophthalmoscopy. Ultrawide-field fundus images ofthe right eye without central retinal vein occlusion (CRVO) (A) and with CRVO (B).Journal of Ophthalmology3using the Youden index [31]. +e ROC curve was calculatedusing scikit-learn, and CIs for sensitivity and specificitywere determined using SciPy. +e pairedt-test was used tocompare AUCs between the DL and the SVM models.3. ResultsWe used 125 CRVO images from 125 patients (mean age,67.8±13.9 years; 67 men and 58 women; 61 left fundus and64 right fundus images) and 238 non-CRVO images from202 subjects (mean age, 68.6±7.9 years; 104 men and 98women; 122 left fundus and 116 right fundus images) in thisanalysis. No significant differences were detected betweenthese two groups with respect to age, gender ratio, and left-right eye image ratio (Table 1).+e DL model’s sensitivity for diagnosing CRVO was98.4% (95% CI, 94.3–99.8%), its specificity was 97.9% (95%CI, 94.6–99.1%), and the AUC was 0.989 (95% CI, 0.980–0.999); in contrast, sensitivity of the SVM model was 84.0%(95% CI, 76.3–89.3%), its specificity was 87.5% (95% CI,82.7–91.1%), and the AUC was 0.895 (95% CI, 0.859–0.931).In ROC curves, AUC of the DL model was significantlyhigher than that of the SVM model (P<0.001) (Figure 3).A composite image, comprising the fundal imagesuperimposed with its corresponding heat map, was createdby the DNN, and these images showed that DNNs couldaccurately identify crucial areas in the fundal images;a representative composite image is presented in Figure 4.Blue was used to indicate the strength of DNN-basedidentification, and an increase in color intensity was ob-served in areas with retinal hemorrhage and at the focuspoints. +us, in non-CRVO images, the heat map showedthat focal points accumulated around the optic disc, whereasin CRVO images, focal points accumulated around the opticdisc and around retinal hemorrhages. +ese results implythat DNNs may be able to distinguish between CRVO eyesand normal eyes by identifying and highlighting retinalhemorrhages.4. Discussion+e fundamental aim of this study was to explore thepossibility of early detection of CRVO from Optos fundusphotographs using DL-based algorithms. If screening forCRVO is possible noninvasively and without the use ofmydriatic agents, this approach would be medically viable.Currently, it is unreasonable to expect ophthalmologists tointerpret all Optos-acquired fundus images because of as-sociated medical resource costs. +erefore, a DL model thatcan accurately diagnose conditions based on ultrawide-fieldfundus ophthalmoscopy images without the need for humaninput can be used to screen and diagnose a very largenumber of patients at a very low cost.Here, we have used DL technology to identify Optosimages that show presence of CRVO. Our results show thatthe DL model has higher sensitivity, specificity, and AUCvalues than the SVM model for detecting CRVO in Optos-derived fundus photographs.Further, using heat maps, we show that DNN couldaccurately identify an area around the optic disc in the non-CRVO images, whereas in CRVO images, it focused on thearea around the optic disc and could highlight retinalhemorrhages. +is result implies that the proposed DNNmodel may be able to identify CRVO by focusing on areaswith suspected retinal hemorrhages. It is known that DLalgorithm-based models can automatically learn local fea-ture values of images and generate classification models[22, 26, 29, 31]. Additionally, DL includes several layers forthe identification of local features of complicated differences,which can subsequently be combined [29].In recent years, a number of studies have addressed thatCNN hugely outperforms classic ML algorithms in imageclassification tasks [16, 32–34]. Recently, Wang et al. havereported that the performance of the DL model was notsignificantly different from that of the best classical methods,including SVM and human physicians, when classifyingmediastinal lymph node metastasis in nonsmall cell lungcancer using positron emission tomography/computed to-mography images [35]. +is could be because image in-formation necessary for classification was lost during imageconvolution in DL. In contrast, we found that the perfor-mance of the DL model was better than that of the SVMmodel in accurately diagnosing CRVO using Optos images.As most cases of CRVO need early intervention, patientsdiagnosed with CRVO using this method can immediatelyconsult retinal specialists and receive necessary advancedTable1: Patient demographics.CRVO    Non-CRVOpvalueNumber of images(patients)125 (125)    238 (202)—Age (yrs)67.8±13.9   68.6±7.90.489 (Student’st-test)Sex, female58 (46.4%)   98 (48.5%)0.734 (Fisher’sexact test)Left fundus61 (48.8%)  122 (51.3%)0.660 (Fisher’sexact test)Geep2learningY&/) – specificityYensitivity))(wU(wU(w3(w3(wI(wI(wV(wV((Figure3: Receiver operating characteristic (ROC) curve for centralretinal vein occlusion.4Journal of Ophthalmologytreatment at an ophthalmic medical center. +e Optos-basedtelemedicine technology being proposed here could signif-icantly help us in preserving good visual function in CRVOpatients living in areas with inadequate ophthalmic care andcould potentially be used to cover large areas without ad-equate care facilities.Despite the above, our study has a few limitations. First,we have only compared images of normal retinas withCRVO retinas and did not include images of other retinaldiseases. Based on the image examples presented in thisstudy, it may be expected that a CNN algorithm should easilybe able to classify between the two types of images. To usethis model under clinical conditions, further developmentand testing to ensure accurate identification of multipleconditions other than CRVO would be essential. Addi-tionally, clarity of the eye may decrease in patients withmature cataract or severe vitreous hemorrhage, and in suchcases, analysis of images captured using Optos may bedifficult. +us, future studies should extensively evaluate theperformance and versatility of DL using larger samples andwith images of other fundus diseases.5. ConclusionsIn conclusion, the DL model performed better than theSVM model in terms of its ability to distinguish betweenCRVO and normal eyes using ultrawide-field fundusophthalmoscopic images. +is technology has significantpotential clinical usefulness as it can be combined withtelemedicine to reach large areas where no specialist care isavailable.Data Availability+e Optos image datasets and its corresponding super-imposed heat maps analyzed during the current study areavailable from the corresponding author on reasonablerequest.Conflicts of Interest+e authors declare that there are no conflicts of interestregarding the publication of this paper.AcknowledgmentsWe thank Masayuki Miki and orthoptists at TsukazakiHospital for their support in data collection.References[1] J. W. Yau, P. Lee, T. Y. Wong, J. Best, and A. Jenkins, “Retinalvein occlusion: an approach to diagnosis, systemic risk factorsand management,”Internal Medicine Journal, vol. 38, no. 12,pp. 904–910, 2008.[2] S. Rogers, R. L. McIntosh, N. Cheung et al., “+e prevalence ofretinal vein occlusion: pooled data from population studiesfrom the United States, Europe, Asia, and Australia,”Oph-thalmology, vol. 117, no. 2, pp. 313–319, 2010.[3] S. S. Hayreh and M. B. Zimmerman, “Fundus changes incentral retinal vein occlusion,”Retina, vol. 35, no. 1,pp. 29–42, 2015.[4] S. Yeh, S. J. Kim, A. C. Ho et al., “+erapies for macular edemaassociated with central retinal vein occlusion: a report by theFigure4: Representative ultrawide-field fundus images and corresponding heat maps. +e ultrawide-field fundus image without centralretinal vein occlusion (CRVO) (A), and its corresponding superimposed heat map (B); with CRVO (C), and its corresponding superimposedheat map (D). In the image without CRVO (A), the deep convolution neural network focused on the optic disc (blue), whereas in the imagewith CRVO (B), the model focused on the optic disc and on the retinal hemorrhages (blue) (D).Journal of Ophthalmology5American Academy of Ophthalmology,”Ophthalmology,vol. 122, no. 4, pp. 769–778, 2015.[5] P. A. Campochiaro, D. M. Brown, C. C. Awh et al., “Sustainedbenefits from ranibizumab for macular edema followingcentral retinal vein occlusion: twelve-month outcomes ofa  phase  III  study,”Ophthalmology,  vol.  118,  no.  10,pp. 2041–2049, 2011.[6] D. M. Brown, J. S. Heier, W. L. Clark et al., “Intravitrealaflibercept injection for macular edema secondary to centralretinal vein occlusion: 1-year results from the phase 3COPERNICUS study,”American  Journal  of  Ophthalmology,vol. 155, no. 3, pp. 429–437, 2013.[7] J. F. Korobelnik, F. G. Holz, J. Roider et al., “Intravitrealaflibercept injection for macular edema resulting from centralretinal vein occlusion: one-year results of the phase 3 GALILEOstudy,”Ophthalmology, vol. 121, no. 1, pp. 202–208, 2014.[8] M. Mrsnik,Global   Aging   2013:   Rising   to   the   Challenge,Standard & Poor’s Rating Services, 2013, https://www.nact.org/resources/2013_NACT_Global_Aging.pdf.[9] A. Nagiel, R. A. Lalane, S. R. Sadda, and S. D. Schwarttz,“Ultra-wide field fundus imaging: a review of clinical appli-cations and future trends,”Retina, vol. 36, no. 4, pp. 660–678,2016.[10] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,”Nature,vol. 521, no. 7553, pp. 436–444, 2015.[11] S. Liu, S. Liu, W. Cai et al., “Multimodal neuroimaging featurelearning for multiclass diagnosis of Alzheimer’s disease,”IEEETransactions   on   Biomedical   Engineering, vol. 62, no. 4,pp. 1132–1140, 2015.[12] G. Litjens, C. I. S ́anchez, N. Timofeeva et al., “Deep learning asa tool for increased accuracy and efficiency of histopatho-logical diagnosis,”Scientific Reports, vol. 6, no.1, article 26286,2016.[13] V. Gulshan, L. Peng, M. Coram et al., “Development andvalidation of a deep learning algorithm for detection of di-abetic retinopathy in retinal fundus photographs,”JAMA,vol. 316, no. 22, pp. 2402–2410, 2016.[14] W. H. Pinaya, A. Gadelha, O. M. Doyle et al., “Using deepbelief network modelling to characterize differences in brainmorphometry in schizophrenia,”Scientific  Reports, vol. 6,no. 1, article 38897, 2016.[15] R. Gargeya and T. Leng, “Automated identification of diabeticretinopathy using deep learning,”Ophthalmology, vol. 124,no. 7, pp. 962–969, 2017.[16] H. Ohsugi, H. Tabuchi, H. Enno, and N. Ishitobi, “Accuracy ofdeep learning, a machine-learning technology, using ultra-wide-field fundus ophthalmoscopy for detecting rhegma-togenous retinal detachment,”Scientific Reports, vol. 7, no. 1,p. 9425, 2017.[17] F. Mosteller and J. W. Tukey, “Data analysis, including sta-tistics,” inHandbook of Social Psychology, Research Methods,G. Lindzey and E. Aronson, Eds., Vol. 2, Addison-Wesley,Reading, MA, USA, 1968.[18]R. Kohavi, “A study of cross-validation and bootstrap for ac-curacy estimation and model selection,” inProceedings of In-ternational  Joint  Conference  on  Artificial  Intelligence  (IJCAI),pp. 1137–1145, Stanford University, Stanford, CA, USA, 1995.[19] D. M. Maslove, T. Podchiyska, and H. J. Lowe, “Discretizationof continuous features in clinical datasets,”Journal  of  theAmerican  Medical  Informatics  Association, vol. 20, no. 3,pp. 544–553, 2013.[20] H. A. Sturges, “+e choice of a class interval,”Journal of theAmerican  Statistical  Association, vol. 21, no. 153, pp. 65-66,1926.[21] A. K. Akobeng, “Understanding diagnostic tests 3: receiveroperating characteristic curves,”Acta  Paediatrica, vol. 96,no. 5, pp. 644–647, 2007.[22] J. Deng, W. Dong, R. Socher, L. J. Li, K. Li, and L. Fei-Fei,“Imagenet: a large-scale hierarchical image database,” inProceedings  of  IEEE  Conference  on  Computer  Vision  andPattern Recognition, pp. 248–255, 2009.[23] O. Russakovsky, J. Deng, H. Su et al., “Imagenet large scalevisual recognition challenge,”International Journal of Com-puter Vision, vol. 115, no. 3, pp. 211–252, 2015.[24] C. Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu, “Deeply-supervised nets,” inProceedings  of  18th  International  Con-ference on Artificial Intelligence and Statistics AISTATS, vol. 2,San Diego, CA, USA, 2015.[25] D. Scherer, M. Andreas, and B. Sven, “Evaluation of poolingoperations in convolutional architectures for object recog-nition,” inProceedings of 20th International Artificial NeuralNetworks–ICANN, pp. 92–101, +essaloniki, Greece, 2010.[26] J. Redmon, S. Divvala, R. Girshick, and F. Farhadi, “You onlylook once: unified, real-time object detection,” arXivpreprintarXiv; 1506.02640, 2015.[27] P. Agrawal, R. Girshick, and J. Malik, “Analyzing the per-formance of multilayer neural networks for object recogni-tion,” inProceedings  of  European  Conference  on  ComputerVision, pp. 329–344, Zurich, Switzerland, 2014.[28] N. Qian, “On the momentum term in gradient descentlearning  algorithms,”Neural   Networks,  vol. 12,  no. 1,pp. 145–151, 1999.[29] Y. Nesterov, “A method for unconstrained convex minimi-zation problem with the rate of convergence O (1/k2),”Doklady AN USSR, vol. 269, pp. 543–547, 1983.[30] R. G. Brereton and G. R. Lloyd, “Support vector machines forclassification and regression,”Analyst, vol. 135, no. 2,pp. 230–267, 2010.[31] E. F. Schisterman, D. Faraggi, B. Reiser, and J. Hu, “YoudenIndex and the optimal threshold for markers with mass atzero,”Statistics in Medicine, vol. 27, no. 2, pp. 297–315, 2008.[32] C. Quan, L. Hua, X. Sun, and W. Bai, “Multichannel con-volutional neural network for biological relation extraction,”BioMed Research International, vol. 2016, Article ID 1850404,10 pages, 2016.[33] S. B. Seong, C. Pae, and H. J. Park, “Geometric convolutionalneural network for analyzing surface-based neuroimagingdata,”Frontiers in Neuroinformatics, vol. 12, p. 42, 2018.[34] T. Maruyama, N. Hayashi, Y. Sato et al., “Comparison ofmedical image classification accuracy among three machinelearning methods,”Journal of X-Ray Science and Technology,pp. 1–9, 2018.[35] H. Wang, Z. Zhou, Y. Li et al., “Comparison of machinelearning methods for classifying mediastinal lymph nodemetastasis of non-small cell lung cancer from 18F-FDG PET/CT images,”EJNMMI Research, vol. 7, no. 1, p. 11, 2017.6Journal of OphthalmologyStem Cells InternationalHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018M E D I AT O R SI N F LA M M AT I O NofEndocrinologyInternational Journal ofHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Disease MarkersHindawiwww.hindawi.comVolume 2018BioMed Research InternationalOncologyJournal ofHindawiwww.hindawi.comVolume 2013Hindawiwww.hindawi.comVolume 2018Oxidative Medicine and Cellular LongevityHindawiwww.hindawi.comVolume 2018PPAR ResearchHindawi Publishing Corporation http://www.hindawi.comVolume 2013Hindawiwww.hindawi.comThe Scientific World JournalVolume 2018Immunology ResearchHindawiwww.hindawi.comVolume 2018Journal ofObesityJournal ofHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018 Computational and  Mathematical Methods in MedicineHindawiwww.hindawi.comVolume 2018Behavioural NeurologyOphthalmologyJournal ofHindawiwww.hindawi.comVolume 2018Diabetes ResearchJournal ofHindawiwww.hindawi.comVolume 2018Hindawiwww.hindawi.comVolume 2018Research and TreatmentAIDSHindawiwww.hindawi.comVolume 2018Gastroenterology Research and PracticeHindawiwww.hindawi.comVolume 2018Parkinson’s DiseaseEvidence-Based Complementary andAlternative MedicineVolume 2018Hindawiwww.hindawi.comSubmit your manuscripts atwww.hindawi.comCopyrightofJournalofOphthalmologyisthepropertyofHindawiLimitedanditscontentmaynotbecopiedoremailedtomultiplesitesorpostedtoalistservwithoutthecopyrightholder'sexpresswrittenpermission.However,usersmayprint,download,oremailarticlesforindividualuse.